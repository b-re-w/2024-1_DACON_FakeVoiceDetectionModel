{
 "cells": [
  {
   "cell_type": "code",
   "id": "129e2e36",
   "metadata": {},
   "source": [
    "%%capture\n",
    "!pip install speechbrain\n",
    "!pip install transformers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "459e3a33",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "import torchaudio\n",
    "from speechbrain.inference.VAD import VAD\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "from speechbrain.inference.separation import SepformerSeparation as separator\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1d2e38c-26e3-4052-a68a-17c353dab7b9",
   "metadata": {},
   "source": [
    "VAD = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir='./.cache/vad-crdnn-libriparty', run_opts={\"device\":\"cuda\"})\n",
    "model = separator.from_hparams(source=\"speechbrain/sepformer-libri2mix\", savedir='./.cache/sepformer-libri2mix', run_opts={\"device\":\"cuda\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88620cd0",
   "metadata": {},
   "source": [
    "est_sources = model.separate_file(path='speechbrain/sepformer-wsj02mix/test_mixture.wav')\n",
    "est_sources.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2effffaf-bb6e-4d41-8f49-e222ef85e92b",
   "metadata": {},
   "source": [
    "Audio(\"./audio_cache/test_mixture.wav\", rate=8000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b6b34af",
   "metadata": {},
   "source": [
    "signal = read_audio(\"./audio_cache/test_mixture.wav\").squeeze()\n",
    "Audio(signal, rate=8000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b12fb6316abd88d",
   "metadata": {},
   "source": [
    "est_sources.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "39f19afe",
   "metadata": {},
   "source": [
    "Audio(est_sources[:, :, 0].detach().cpu().squeeze(), rate=8000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dec85f65",
   "metadata": {},
   "source": [
    "Audio(est_sources[:, :, 1].detach().cpu().squeeze(), rate=8000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "759eb92c-052e-4cd4-b88c-6103242450cc",
   "metadata": {},
   "source": [
    "est_sources[:, :, 0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9fefc86-2829-4f91-9afe-263f9adb024b",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"./data/test.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f1df92a-f63d-441f-9a6e-4b61b610bc60",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f65f2fcd-8c61-4ff3-ae40-a2e841e0fc73",
   "metadata": {},
   "source": [
    "df['id']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ee100c1-8ce0-43a1-8e5f-ef11fe83899f",
   "metadata": {},
   "source": [
    "if not os.path.isdir(\"./data/test_splitted\"):\n",
    "    os.mkdir(\"./data/test_splitted\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3f55371-1401-4962-b05b-e30ce506a2f5",
   "metadata": {},
   "source": [
    "labels = dict(id=[], path0=[], path1=[], label0=[], label1=[])\n",
    "\n",
    "for _id in zip(tqdm(df['id'])):\n",
    "    est_sources = model.separate_file(path=f\"./data/test/{_id}.ogg\")\n",
    "    \n",
    "    if not os.path.isdir(f\"./data/test_splitted/{_id}/\"):\n",
    "        os.mkdir(f\"./data/test_splitted/{_id}/\")\n",
    "    \n",
    "    labels['id'].append(_id)\n",
    "    sample_rate = 8000\n",
    "    \n",
    "    file0_path = f\"./data/test_splitted/{_id}/0.wav\"\n",
    "    labels['path0'] = file0_path\n",
    "    torchaudio.save(file0_path, est_sources[:, :, 0].detach().cpu(), sample_rate)\n",
    "    boundaries = VAD.get_speech_segments(file0_path)\n",
    "    print(boundaries)\n",
    "    labels['label0'] = \"speech\" if 'SPEECH' in boundaries else \"noise\"\n",
    "\n",
    "    file1_path = f\"./data/test_splitted/{_id}/1.wav\"\n",
    "    labels['path1'] = file1_path\n",
    "    torchaudio.save(file1_path, est_sources[:, :, 1].detach().cpu(), sample_rate)\n",
    "    boundaries = VAD.get_speech_segments(file1_path)\n",
    "    labels['label1'] = \"speech\" if 'SPEECH' in boundaries else \"noise\"\n",
    "\n",
    "pd.DataFrame(labels).to_csv(f\"./data/test_splitted.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
