{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SW중심대학 디지털 경진대회_SW와 생성AI의 만남 : AI부문\n",
    " - 이 AI 경진대회에서는 5초 분량의 오디오 샘플에서 진짜 사람 목소리와 AI가 생성한 가짜 목소리를 정확하게 구분할 수 있는 모델을 개발하는 것이 목표입니다.\n",
    " - 이 작업은 보안, 사기 감지 및 오디오 처리 기술 향상 등 다양한 분야에서 매우 중요합니다."
   ],
   "id": "840dc88f7c14e1fa"
  },
  {
   "cell_type": "markdown",
   "id": "361d73a1",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2024-04-08T18:51:47.130888",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.123877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports\n",
    "모델 학습 및 추론에 사용할 라이브러리들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "id": "bbadbd56",
   "metadata": {
    "papermill": {
     "duration": 12.650384,
     "end_time": "2024-04-08T18:51:59.788340",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.137956",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-04T20:27:59.247812Z",
     "start_time": "2024-07-04T20:27:55.122422Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2d80cf24-13e8-480c-94eb-2982bb52510d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:27:59.255263Z",
     "start_time": "2024-07-04T20:27:59.251753Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f64eb379-e527-46c4-8b12-ead8db628070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:27:59.320548Z",
     "start_time": "2024-07-04T20:27:59.256276Z"
    }
   },
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Using device -\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device - cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "a0d2de5d",
   "metadata": {
    "papermill": {
     "duration": 0.007241,
     "end_time": "2024-04-08T18:51:59.803571",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.796330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config\n",
    "- 딥러닝 모델을 학습하기 전에 설정해야하는 다양한 매개변수를 정의하는 설정 클래스입니다.\n",
    "- 클래스를 사용하여 학습에 필요한 설정 값을 미리 지정합니다.\n",
    "\n",
    "##### 오디오 신호\n",
    "- 우리가 듣는 소리는 공기의 압력 변화로, 이것을 디지털 신호로 변환한 것이 오디오 신호입니다.\n",
    "- 이 신호는 시간에 따라 변하는 진폭 값을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "id": "1a32fb60",
   "metadata": {
    "papermill": {
     "duration": 0.016983,
     "end_time": "2024-04-08T18:51:59.828208",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.811225",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-04T20:27:59.326223Z",
     "start_time": "2024-07-04T20:27:59.321554Z"
    }
   },
   "source": [
    "class CONFIG:\n",
    "    \"\"\" Configuration Class \"\"\"\n",
    "    SEED = 202102545  # 재현성을 위해 랜덤 시드 고정\n",
    "    \n",
    "    \"\"\" SR(Sample Rate)\n",
    "    - 오디오 데이터의 샘플링 레이트를 설정합니다.\n",
    "    - 높은 샘플링 레이트는 더 높은 주파수의 소리를 캡처할 수 있지만, 처리에 더 많은 계산 자원이 필요합니다.\n",
    "    - 오디오 데이터의 초당 샘플 수를 정의합니다.\n",
    "    \"\"\"\n",
    "    SR = 32000\n",
    "\n",
    "    \"\"\" ROOT_FOLDER\n",
    "    - 데이터셋의 루트 폴더 경로를 설정합니다.\n",
    "    \"\"\"\n",
    "    ROOT_FOLDER = os.path.join(\".\", \"data\")\n",
    "    \n",
    "    \"\"\" BATCH_SIZE\n",
    "    - 학습 시 한 번에 처리할 데이터 샘플의 수를 정의합니다\n",
    "    - 큰 배치 크기는 메모리 사용량을 증가시키지만, 학습 속도를 높입니다.\n",
    "    \"\"\"\n",
    "    BATCH_SIZE = 100\n",
    "    \n",
    "    \"\"\" N_EPOCHS\n",
    "    - 전체 데이터셋을 학습할 횟수를 정의합니다.\n",
    "    - 에폭 수가 너무 적으면 과소적합이 발생할 수 있고, 너무 많으면 과적합이 발생할 수 있습니다.\n",
    "    \"\"\"\n",
    "    N_EPOCHS = 200\n",
    "    \n",
    "    \"\"\" LR (Learning Rate)\n",
    "    - 모델의 가중치를 업데이트할 때 사용되는 학습 속도를 정의합니다.\n",
    "    - 학습률이 너무 크면 학습이 불안정해질 수 있고, 너무 작으면 학습 속도가 느려집니다.\n",
    "    \"\"\"\n",
    "    LR = 1e-5"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6700bf8e-7f43-4eac-9bea-25eb1d95fb12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:27:59.337618Z",
     "start_time": "2024-07-04T20:27:59.328234Z"
    }
   },
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\" Fixed RandomSeed\n",
    "    아래의 코드는 머신러닝이나 딥러닝 모델을 훈련할 때, 결과의 재현성을 보장하기 위해 사용되는 함수입니다.\n",
    "    이 함수는 다양한 랜덤 시드를 고정하여, 실행할 때마다 동일한 결과를 얻기 위해 사용됩니다.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG.SEED)  # Seed 고정"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8a682d49",
   "metadata": {
    "papermill": {
     "duration": 0.007331,
     "end_time": "2024-04-08T18:52:31.507909",
     "exception": false,
     "start_time": "2024-04-08T18:52:31.500578",
     "status": "completed"
    },
    "tags": []
   },
   "source": "## Dataset"
  },
  {
   "cell_type": "code",
   "id": "d2459913-1bf6-40b9-b07d-402699590b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:03.204037Z",
     "start_time": "2024-07-04T20:27:59.339237Z"
    }
   },
   "source": [
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "\n",
    "class ContrastingVoiceDataset(Dataset):\n",
    "    download_url = \"https://drive.usercontent.google.com/download?id=1hi1dibkHyFbaxAteLlZJw6r3g9ddd4Lf&export=download&authuser=0&confirm=t&uuid=c40c278b-d74b-4b75-bc79-09e8a3ccffa4&at=APZUnTUvIVFVM9gjGNUCmDb4YZCy%3A1719807236671\"\n",
    "    \n",
    "    @classmethod\n",
    "    def download(cls, root='./data', filename=\"download.zip\", md5=None):\n",
    "        cls.download_root = root\n",
    "        filepath = os.path.join(root, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            download_and_extract_archive(cls.download_url, root, root, filename, md5)\n",
    "            print(\"Extraction completed.\")\n",
    "        else:\n",
    "            print(f\"File already exists in {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def get_dataset_path(cls, root, train=True):\n",
    "        return os.path.join(root, \"train.csv\" if train else \"test.csv\")\n",
    "\n",
    "    @property\n",
    "    def submission_form_path(cls):\n",
    "        return os.path.join(cls.download_root, \"sample_submission.csv\")\n",
    "    \n",
    "    def __init__(self, root=\"./data\", train=True, split_ratio=1, transform=None):\n",
    "        \"\"\"\n",
    "        Voice Dataset for Contrastive Learning\n",
    "        \n",
    "        :param root: The path to the data directory\n",
    "        :param train: is train or test\n",
    "        :param split_ratio: split ratio for train(can be 0.5 or above) and valid(can be lower than 0.5) set\n",
    "        :param transform: data transformer\n",
    "        :param target_transform: label transformer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.download(root)\n",
    "        self.download_root = root\n",
    "        self.is_train = train\n",
    "\n",
    "        raw_data = self._load_data(self.get_dataset_path(root, train), split_ratio if split_ratio >= 0.5 else 1-split_ratio)\n",
    "        if split_ratio >= 0.5:\n",
    "            self.raw_data, _ = raw_data\n",
    "        else:\n",
    "            _, self.raw_data = raw_data\n",
    "            \n",
    "        self.multi_label = 'path' not in self.raw_data.columns\n",
    "        \n",
    "        self.ids = self.raw_data['id']\n",
    "        if self.multi_label:\n",
    "            self.data = [self.raw_data['path0'], self.raw_data['path1']]\n",
    "            self.label = [self.raw_data['label0'], self.raw_data['label1']]\n",
    "        else:\n",
    "            self.data = self.raw_data['path']\n",
    "            if 'label' in self.raw_data.columns:\n",
    "                self.label = self.raw_data['label']\n",
    "            else:\n",
    "                self.label = None\n",
    "\n",
    "        self.transforms(transform)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_data(dataset_path, split_ratio):\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        \n",
    "        if split_ratio == 1 or split_ratio == 0:\n",
    "            return (df, None) if split_ratio == 1 else (None, df)\n",
    "            \n",
    "        df1, df2, _, _ = split(df, df['label'], test_size=1-split_ratio, random_state=202102545)\n",
    "        return df1, df2\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_id_from_path(path: str):\n",
    "        return [pth for pth in path.replace(\"/0.ogg\", \".ogg\").split(\"/\") if '.ogg' in pth][0].replace(\".ogg\", \"\")\n",
    "\n",
    "    def transforms(self, transform=None):\n",
    "        if transform is not None:\n",
    "            if not isinstance(transform, list) and not isinstance(transform, tuple):\n",
    "                transform = [transform]\n",
    "            for t in transform:\n",
    "                self.ids, self.data, self.label = t(self.ids, self.data, self.label)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.multi_label:\n",
    "            return len(self.data[0])\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            if self.multi_label:\n",
    "                return [d[index] for d in self.data], [l[index] for l in self.label], self.ids[index]\n",
    "            return self.data[index], self.label[index], self.ids[index]\n",
    "        return self.data[index], self.ids[index]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:03.211974Z",
     "start_time": "2024-07-04T20:28:03.205047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_list(multi_label=False):\n",
    "    def to_list_inner(ids, datas, labels):\n",
    "        ids = [_id for _id in ids]\n",
    "        if not multi_label:\n",
    "            datas, labels = [datas], [labels]\n",
    "        datas = [[d for d in data] for data in datas]\n",
    "        try:\n",
    "            labels = [[l for l in label] for label in labels]\n",
    "        except TypeError:\n",
    "            pass\n",
    "        if not multi_label:\n",
    "            datas, labels = datas[0], labels[0]\n",
    "        return ids, datas, labels\n",
    "    return to_list_inner"
   ],
   "id": "1d5b79398623de5b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:03.514291Z",
     "start_time": "2024-07-04T20:28:03.212982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ContrastingVoiceDataset(root=CONFIG.ROOT_FOLDER, train=True, split_ratio=0.8, transform=to_list())\n",
    "valid_dataset = ContrastingVoiceDataset(root=CONFIG.ROOT_FOLDER, train=True, split_ratio=0.2, transform=to_list())\n",
    "test_dataset = ContrastingVoiceDataset(root=CONFIG.ROOT_FOLDER, train=False, split_ratio=1, transform=to_list())\n",
    "\n",
    "print(\"Query Dataset for checking:\", train_dataset[0])\n",
    "train_dataset.raw_data"
   ],
   "id": "8967c36f6abc224b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists in .\\data\\download.zip\n",
      "File already exists in .\\data\\download.zip\n",
      "File already exists in .\\data\\download.zip\n",
      "Query Dataset for checking: ('./train/BIQYKAWL.ogg', 'fake', 'BIQYKAWL')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             id                  path label\n",
       "23745  BIQYKAWL  ./train/BIQYKAWL.ogg  fake\n",
       "8355   WTCXWLEU  ./train/WTCXWLEU.ogg  fake\n",
       "34884  MRZQEWBF  ./train/MRZQEWBF.ogg  real\n",
       "14462  OHLGZHAF  ./train/OHLGZHAF.ogg  fake\n",
       "43295  FRZNSAKS  ./train/FRZNSAKS.ogg  fake\n",
       "...         ...                   ...   ...\n",
       "7636   FFZRTCWE  ./train/FFZRTCWE.ogg  fake\n",
       "44556  CRTOENWR  ./train/CRTOENWR.ogg  fake\n",
       "19320  IHSKSRCJ  ./train/IHSKSRCJ.ogg  real\n",
       "15989  HGESQVRG  ./train/HGESQVRG.ogg  fake\n",
       "46035  ZANVRAYM  ./train/ZANVRAYM.ogg  fake\n",
       "\n",
       "[44350 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23745</th>\n",
       "      <td>BIQYKAWL</td>\n",
       "      <td>./train/BIQYKAWL.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8355</th>\n",
       "      <td>WTCXWLEU</td>\n",
       "      <td>./train/WTCXWLEU.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34884</th>\n",
       "      <td>MRZQEWBF</td>\n",
       "      <td>./train/MRZQEWBF.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14462</th>\n",
       "      <td>OHLGZHAF</td>\n",
       "      <td>./train/OHLGZHAF.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43295</th>\n",
       "      <td>FRZNSAKS</td>\n",
       "      <td>./train/FRZNSAKS.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>FFZRTCWE</td>\n",
       "      <td>./train/FFZRTCWE.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44556</th>\n",
       "      <td>CRTOENWR</td>\n",
       "      <td>./train/CRTOENWR.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>IHSKSRCJ</td>\n",
       "      <td>./train/IHSKSRCJ.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>HGESQVRG</td>\n",
       "      <td>./train/HGESQVRG.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46035</th>\n",
       "      <td>ZANVRAYM</td>\n",
       "      <td>./train/ZANVRAYM.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44350 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:03.610557Z",
     "start_time": "2024-07-04T20:28:03.515298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# apply seperated dataset\n",
    "ContrastingVoiceDataset.get_dataset_path = lambda self, root, train=True: os.path.join(root, \"train.csv\" if train else \"test_separated.csv\")\n",
    "test_dataset = ContrastingVoiceDataset(root=CONFIG.ROOT_FOLDER, train=False, split_ratio=1, transform=to_list(multi_label=True))"
   ],
   "id": "ba85cb259492f9fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists in .\\data\\download.zip\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Data Transformation",
   "id": "d7888fecea819346"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:04.429945Z",
     "start_time": "2024-07-04T20:28:03.612389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import wespeaker\n",
    "\n",
    "\n",
    "def get_resnet152():\n",
    "    model_id = \"Wespeaker/wespeaker-voxceleb-resnet152-LM\"\n",
    "    model_name = model_id.replace(\"Wespeaker/wespeaker-\", \"\").replace(\"-\", \"_\")\n",
    "\n",
    "    root_dir = hf_hub_download(model_id, filename=model_name+\".onnx\").replace(model_name+\".onnx\", \"\")\n",
    "\n",
    "    import os\n",
    "    if not os.path.isfile(root_dir+\"avg_model.pt\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".pt\"), root_dir+\"avg_model.pt\")\n",
    "    if not os.path.isfile(root_dir+\"config.yaml\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".yaml\"), root_dir+\"config.yaml\")\n",
    "\n",
    "    resnet = wespeaker.load_model_local(root_dir)\n",
    "    resnet.set_gpu(-1 if device == torch.device('cpu') else 0)\n",
    "\n",
    "    def resnet152(pcm, sample_rate=None):\n",
    "        if isinstance(pcm, str):\n",
    "            return resnet.extract_embedding(pcm)\n",
    "        else:\n",
    "            pass  # TODO: 메모리에 로드된 상태의 오디오 처리 코드 필요\n",
    "            #return extract_embedding(resnet, pcm, sample_rate)\n",
    "\n",
    "    print(f\"ResNet152 Model Loaded on {resnet.device}\")\n",
    "    return resnet152"
   ],
   "id": "b02f83258987e0c8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:04.439826Z",
     "start_time": "2024-07-04T20:28:04.431956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_embedding_file = \"train_embedding.pt\"\n",
    "valid_embedding_file = \"valid_embedding.pt\"\n",
    "test_embedding_file = \"test_embedding.pt\"\n",
    "\n",
    "\n",
    "def get_pretrained_embedding():\n",
    "    if not os.path.isfile(train_embedding_file) \\\n",
    "            or not os.path.isfile(valid_embedding_file) \\\n",
    "            or not os.path.isfile(test_embedding_file):\n",
    "        return get_resnet152()\n",
    "    else:\n",
    "        train_embedding = torch.load(train_embedding_file)\n",
    "        valid_embedding = torch.load(valid_embedding_file)\n",
    "        test_embedding = torch.load(test_embedding_file)\n",
    "        dataset_list = {\n",
    "            len(train_embedding): train_embedding,\n",
    "            len(valid_embedding): valid_embedding,\n",
    "            len(test_embedding[0]): test_embedding\n",
    "        }\n",
    "        print(\"INFO: Pretrained Voice Embedding loaded.\", dataset_list.keys())\n",
    "        \n",
    "        def load_embedding(dataset):\n",
    "            try:\n",
    "                return dataset_list[len(dataset)]\n",
    "            except KeyError:\n",
    "                return dataset_list[len(dataset[0])]\n",
    "        \n",
    "        load_embedding.__dict__['pretrained'] = True\n",
    "        return load_embedding"
   ],
   "id": "551b0bd63cae9387",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:12.870936Z",
     "start_time": "2024-07-04T20:28:04.440836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_embedding(pretrained=get_pretrained_embedding(), sample_rate=CONFIG.SR, multi_label=False):\n",
    "    get_pth = lambda path: os.path.join(CONFIG.ROOT_FOLDER, *path[1:].split(\"/\"))\n",
    "    \n",
    "    if not pretrained:\n",
    "        def extract_embedding(ids, datas, labels):  # TODO: 임베딩 코드 추가 필요\n",
    "            return ids, [torchaudio.load(data) for data in datas], labels\n",
    "        return extract_embedding\n",
    "    \n",
    "    def pretrained_embedding(ids, dataset, labels):\n",
    "        if pretrained.__dict__.get('pretrained'):\n",
    "            new_dataset = pretrained(dataset)\n",
    "            print(\"INFO: Voice Embedding extracted.\")\n",
    "        else:\n",
    "            if multi_label:\n",
    "                new_dataset = []\n",
    "                \n",
    "                for idx, dset in enumerate(tqdm(dataset)):\n",
    "                    lst = []\n",
    "                    new_dataset.append(lst)\n",
    "                    for data in tqdm(dset):\n",
    "                        lst.append(pretrained(get_pth(data), sample_rate))\n",
    "\n",
    "                dataset_size = len(new_dataset[0])\n",
    "            else:\n",
    "                new_dataset = []\n",
    "\n",
    "                for data in tqdm(dataset):\n",
    "                    new_dataset.append(pretrained(get_pth(data), sample_rate))\n",
    "\n",
    "                dataset_size = len(new_dataset)\n",
    "\n",
    "            torch.save(new_dataset, \"nonamed.pt\")\n",
    "            if dataset_size == len(train_dataset.raw_data):\n",
    "                os.rename(\"nonamed.pt\", \"train_embedding.pt\")\n",
    "            elif dataset_size == len(valid_dataset.raw_data):\n",
    "                os.rename(\"nonamed.pt\", \"valid_embedding.pt\")\n",
    "            elif dataset_size == len(test_dataset.raw_data):\n",
    "                os.rename(\"nonamed.pt\", \"test_embedding.pt\")\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid Dataset Size - Could not find relevant dataset sized {dataset_size}.\")\n",
    "                \n",
    "            print(\"INFO: Voice Embedding saved.\")\n",
    "                \n",
    "        return ids, new_dataset, labels  # [pretrained(get_pth(path), sample_rate) for path in dataset]\n",
    "    \n",
    "    return pretrained_embedding"
   ],
   "id": "d8c02a7d-dfb6-4f8b-8df1-db2abaa1cb5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pretrained Voice Embedding loaded. dict_keys([44350, 11088, 50000])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:12.875664Z",
     "start_time": "2024-07-04T20:28:12.871945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_tensor_label(ids, datas, labels):\n",
    "    if labels:\n",
    "        labels = [torch.tensor([0]) if lb == \"fake\" else torch.tensor([1]) for lb in labels]\n",
    "    return ids, datas, labels"
   ],
   "id": "2a20f2533794d230",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:13.128186Z",
     "start_time": "2024-07-04T20:28:12.877671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset.transforms(transform=[to_embedding(), to_tensor_label])\n",
    "valid_dataset.transforms(transform=[to_embedding(), to_tensor_label])\n",
    "test_dataset.transforms(transform=to_embedding(multi_label=test_dataset.multi_label))"
   ],
   "id": "6a2a071509e465a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Voice Embedding extracted.\n",
      "INFO: Voice Embedding extracted.\n",
      "INFO: Voice Embedding extracted.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:19.545504Z",
     "start_time": "2024-07-04T20:28:13.129191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_embedding(pretrained=get_pretrained_embedding(), sample_rate=CONFIG.SR, multi_label=False):\n",
    "    get_pth = lambda path: os.path.join(CONFIG.ROOT_FOLDER, *path[1:].split(\"/\"))\n",
    "\n",
    "    if not pretrained:\n",
    "        def extract_embedding(ids, datas, labels):  # TODO: 임베딩 코드 추가 필요\n",
    "            return ids, [torchaudio.load(data) for data in datas], labels\n",
    "        return extract_embedding\n",
    "\n",
    "    def pretrained_embedding(ids, dataset, labels):\n",
    "        if pretrained.__dict__.get('pretrained'):\n",
    "            new_dataset = pretrained(dataset)\n",
    "            print(\"INFO: Voice Embedding extracted.\")\n",
    "        else:\n",
    "            if multi_label:\n",
    "                new_dataset = []\n",
    "\n",
    "                for idx, dset in enumerate(tqdm(dataset)):\n",
    "                    lst = torch.load(test_embedding_file)[idx]\n",
    "                    new_dataset.append(lst)\n",
    "\n",
    "                dataset_size = len(new_dataset[0])\n",
    "            else:\n",
    "                new_dataset = []\n",
    "\n",
    "                for data in tqdm(dataset):\n",
    "                    new_dataset.append(pretrained(get_pth(data), sample_rate))\n",
    "\n",
    "                dataset_size = len(new_dataset)\n",
    "\n",
    "            torch.save(new_dataset, \"nonamed.pt\")\n",
    "            if dataset_size == len(train_dataset.raw_data):\n",
    "                os.rename(\"nonamed.pt\", \"train_embedding.pt\")\n",
    "            elif dataset_size == len(valid_dataset.raw_data):\n",
    "                os.rename(\"nonamed.pt\", \"valid_embedding.pt\")\n",
    "            elif dataset_size == len(test_dataset.raw_data):\n",
    "                os.rename(\"nonamed.pt\", \"test_embedding.pt\")\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid Dataset Size - Could not find relevant dataset sized {dataset_size}.\")\n",
    "\n",
    "            print(\"INFO: Voice Embedding saved.\")\n",
    "\n",
    "        return ids, new_dataset, labels  # [pretrained(get_pth(path), sample_rate) for path in dataset]\n",
    "\n",
    "    return pretrained_embedding"
   ],
   "id": "288983cb697c516d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pretrained Voice Embedding loaded. dict_keys([44350, 11088, 50000])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:19.562178Z",
     "start_time": "2024-07-04T20:28:19.546510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset, index in zip(train_dataset, range(5)):\n",
    "    print(f\"Dataset {index}: {'FAKE' if dataset[1] == torch.tensor([0]) else 'REAL'}\", dataset[0])"
   ],
   "id": "4739bbf8ec8a6c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0: FAKE tensor([-1.8954e-01, -1.5126e-01, -1.9169e-01, -4.9767e-02, -2.0188e-02,\n",
      "         1.5027e-01, -1.2862e-01, -8.1413e-02,  9.6770e-02, -4.1492e-02,\n",
      "        -1.3344e-01,  2.2745e-01, -9.4607e-02,  2.3628e-02, -9.2205e-02,\n",
      "        -5.7748e-02,  6.2188e-02,  1.4654e-01,  8.1550e-03, -2.6165e-01,\n",
      "         5.2159e-02, -3.8855e-02, -1.5270e-01, -1.3968e-01, -1.9361e-01,\n",
      "         3.3684e-01,  1.1788e-01, -1.7271e-02, -2.3159e-01,  1.0430e-01,\n",
      "         1.0551e-01, -6.3770e-02,  2.0027e-01,  1.1449e-01, -1.3287e-01,\n",
      "        -1.8658e-01,  1.6191e-01, -1.0753e-01, -7.6320e-02,  7.8052e-02,\n",
      "         1.2526e-01, -1.3934e-02, -1.0400e-01, -1.3194e-01,  1.5096e-02,\n",
      "        -2.8469e-02, -8.2221e-02, -9.4001e-02, -2.0316e-01,  1.8863e-01,\n",
      "        -7.0268e-02, -1.8608e-01,  4.7674e-02, -9.2132e-02, -2.4339e-01,\n",
      "        -2.8908e-03, -4.8591e-02, -2.5877e-01,  7.3877e-02, -4.3380e-02,\n",
      "         3.3759e-02, -6.5845e-02, -2.2777e-02, -5.2064e-02,  2.6466e-01,\n",
      "         8.9427e-02, -7.9455e-02,  1.7452e-01, -1.3425e-01, -2.9020e-02,\n",
      "        -1.5479e-01, -2.0307e-01, -4.4050e-02,  4.8118e-02,  4.2728e-02,\n",
      "         2.2446e-01,  1.0268e-01, -1.3212e-01,  2.4964e-01, -6.6730e-02,\n",
      "         1.1519e-02, -4.7426e-02,  1.4212e-01, -4.2034e-01, -1.2370e-01,\n",
      "         9.4701e-02,  6.6795e-02, -2.7367e-01,  2.8834e-02, -1.7856e-02,\n",
      "        -7.1611e-02,  7.5390e-02,  1.0781e-01, -6.4714e-02,  1.0956e-02,\n",
      "        -2.7675e-02,  7.4523e-02, -3.7864e-03, -1.3713e-01, -1.7932e-01,\n",
      "         2.1886e-01,  5.3375e-02,  5.5242e-03,  1.5051e-01,  1.3885e-01,\n",
      "        -3.1971e-02,  4.9733e-02, -2.0234e-01, -1.9718e-01,  3.7351e-02,\n",
      "         1.4374e-02,  9.5399e-02,  3.0633e-02, -2.3125e-01, -1.2895e-01,\n",
      "        -1.7931e-01,  1.3118e-01,  7.1048e-03,  4.0371e-03,  1.3790e-01,\n",
      "         7.4192e-02, -2.3913e-01, -4.0438e-02, -1.0533e-01, -1.6518e-01,\n",
      "        -2.4224e-02, -3.0656e-03,  1.6246e-01, -1.3989e-01, -1.4814e-01,\n",
      "        -1.1734e-02,  1.0850e-01,  8.2474e-02, -2.1804e-01,  8.6089e-02,\n",
      "        -7.3547e-02,  6.7276e-02,  2.0268e-01,  6.2567e-03, -3.1129e-01,\n",
      "        -9.1326e-02, -2.7650e-01, -1.0625e-03,  3.9346e-01, -2.5377e-01,\n",
      "        -7.6900e-02,  5.2424e-02, -3.6978e-01, -1.1253e-01,  3.1326e-01,\n",
      "         2.3898e-02, -1.6402e-01,  2.8746e-02,  4.8696e-02,  1.2569e-01,\n",
      "        -8.8536e-02,  1.0820e-01,  2.6753e-01,  4.1955e-02,  1.0160e-01,\n",
      "        -1.8190e-01, -9.2929e-02,  2.5430e-05,  1.5066e-02, -1.0016e-01,\n",
      "         2.8577e-02,  1.7772e-01,  1.7911e-01,  1.0131e-01,  8.6486e-02,\n",
      "        -1.1321e-01,  5.2792e-02, -1.5718e-01, -6.8814e-03,  5.4382e-03,\n",
      "         5.7395e-02,  2.0787e-02, -6.2848e-02, -5.0350e-02,  3.4838e-01,\n",
      "        -1.3544e-01,  3.7607e-02, -5.4538e-02, -2.2649e-01,  1.4252e-01,\n",
      "         3.5603e-02, -5.1635e-02,  4.8465e-02, -9.1450e-02, -1.4971e-01,\n",
      "        -1.5068e-01,  1.9166e-01, -1.0946e-01, -2.3140e-01, -1.8635e-01,\n",
      "         9.0373e-02,  1.1495e-01, -3.8742e-02,  2.1487e-01, -8.8225e-02,\n",
      "        -2.6981e-01,  1.8713e-01, -1.5273e-01,  2.0055e-01, -5.4212e-02,\n",
      "         6.9522e-02, -1.6101e-01,  1.1321e-01, -1.4165e-01, -6.0233e-02,\n",
      "         2.9212e-02, -1.5117e-01, -5.7281e-02, -3.0739e-01, -1.3560e-01,\n",
      "         2.3074e-01, -8.5934e-02, -1.7675e-02,  1.2702e-01, -6.1722e-02,\n",
      "         7.5711e-02,  5.0511e-02,  5.7220e-02, -1.3352e-01, -8.9721e-02,\n",
      "         1.5265e-04, -4.3355e-02,  1.8958e-01, -2.0969e-01,  2.4037e-01,\n",
      "         2.2973e-01,  1.4501e-01,  2.7194e-01,  1.4876e-01, -4.9135e-02,\n",
      "        -2.6537e-01, -8.9760e-02, -9.3591e-02, -1.1540e-01, -2.1714e-02,\n",
      "         7.1053e-02,  3.7729e-02,  1.2054e-01, -3.3973e-02, -8.1895e-02,\n",
      "         5.8978e-02, -2.0796e-01, -1.4748e-01,  1.9119e-01, -3.1489e-03,\n",
      "        -3.3989e-02, -1.0247e-01,  1.4632e-01,  2.6202e-02,  6.3703e-02,\n",
      "         3.3186e-02])\n",
      "Dataset 1: FAKE tensor([-0.1280, -0.0117,  0.0499,  0.1432, -0.0839, -0.0461,  0.0597, -0.0484,\n",
      "        -0.0440,  0.0561,  0.1248,  0.0525, -0.0055, -0.0767,  0.2200,  0.0345,\n",
      "        -0.0287, -0.0254,  0.0921, -0.0678,  0.0496, -0.0520,  0.1001,  0.1588,\n",
      "        -0.0133, -0.0790, -0.0758, -0.0349,  0.0797, -0.0391,  0.0133,  0.1737,\n",
      "        -0.0878, -0.1414,  0.0413, -0.0631, -0.0398,  0.0206, -0.0665, -0.0073,\n",
      "        -0.0987, -0.0213, -0.0246, -0.0854,  0.0113, -0.0218, -0.0544, -0.1703,\n",
      "        -0.1991,  0.1604, -0.0784,  0.1592,  0.0866,  0.0386, -0.0166,  0.0048,\n",
      "         0.2097, -0.0291,  0.0681,  0.0367,  0.0279, -0.1053,  0.1933,  0.0219,\n",
      "        -0.1701, -0.0917,  0.1156,  0.1536, -0.0068,  0.0977, -0.1523,  0.0574,\n",
      "         0.0370, -0.0493, -0.0155,  0.1300,  0.1074, -0.1507, -0.0259,  0.0599,\n",
      "        -0.0534,  0.2267,  0.0117,  0.2548,  0.1134, -0.1902, -0.0575,  0.1409,\n",
      "        -0.1365, -0.1432, -0.0212, -0.0711, -0.0367,  0.0995,  0.2367, -0.1342,\n",
      "        -0.0959, -0.0883, -0.2670,  0.0184, -0.0159, -0.0538, -0.0177,  0.0189,\n",
      "        -0.0304,  0.0698, -0.0273, -0.0422, -0.0802, -0.0845,  0.0439, -0.0798,\n",
      "        -0.0161, -0.0812, -0.0311,  0.0869,  0.0416,  0.0624,  0.0080, -0.1860,\n",
      "         0.0104,  0.0756,  0.0988,  0.1729, -0.0810, -0.1302, -0.1404, -0.1051,\n",
      "        -0.0094,  0.1996,  0.1536, -0.0023, -0.0184, -0.0214, -0.1480,  0.0364,\n",
      "        -0.2092,  0.1864, -0.0296,  0.0978,  0.1556, -0.0439, -0.0454,  0.0279,\n",
      "         0.0960, -0.0354, -0.0431,  0.0461, -0.0435, -0.1814, -0.0810, -0.0818,\n",
      "        -0.1142, -0.0125, -0.1729,  0.0603, -0.0324,  0.1054,  0.1625, -0.1767,\n",
      "         0.1534,  0.1804, -0.1681, -0.0211, -0.0258,  0.0525, -0.1419,  0.1627,\n",
      "        -0.0333,  0.1630,  0.2240,  0.0263, -0.1366,  0.0450, -0.0231, -0.0191,\n",
      "         0.1462,  0.0948,  0.0690, -0.2244, -0.1224, -0.0919, -0.0484, -0.1332,\n",
      "         0.0387,  0.0653, -0.1754, -0.0345,  0.0883,  0.0988, -0.0728,  0.0626,\n",
      "         0.1231,  0.0841, -0.0504,  0.1508, -0.0070,  0.0071,  0.2182, -0.0615,\n",
      "        -0.0759,  0.0883,  0.1729,  0.0797,  0.1500, -0.1850, -0.0035, -0.1053,\n",
      "        -0.2581,  0.3279,  0.0526,  0.0141, -0.1963,  0.0364, -0.0782,  0.0411,\n",
      "         0.0384,  0.0739,  0.1453, -0.0437, -0.0323,  0.1853,  0.0194, -0.2770,\n",
      "        -0.1624,  0.0460,  0.0070, -0.0026,  0.0717, -0.0129,  0.0874, -0.1579,\n",
      "         0.0148,  0.0454, -0.0914,  0.0252,  0.2251, -0.0907, -0.0495,  0.0640,\n",
      "         0.0220,  0.0542,  0.1720, -0.2105,  0.2048, -0.0617,  0.2734,  0.0913,\n",
      "        -0.0176,  0.0242,  0.1617, -0.1447, -0.0919, -0.1134, -0.0446, -0.0418])\n",
      "Dataset 2: REAL tensor([ 0.0529,  0.1010,  0.1172, -0.0631,  0.0632, -0.1159, -0.0335, -0.0172,\n",
      "         0.1637,  0.0391,  0.0796, -0.0766,  0.0501, -0.0188,  0.0757, -0.1223,\n",
      "        -0.2077,  0.0897,  0.1898,  0.1035, -0.0897, -0.2672,  0.0721,  0.2452,\n",
      "         0.2348,  0.2213, -0.0099,  0.1075,  0.0690, -0.2120,  0.0235,  0.0167,\n",
      "        -0.1776, -0.0702, -0.0985,  0.2446, -0.0017, -0.0182, -0.2660,  0.0888,\n",
      "         0.0833,  0.1668, -0.1144,  0.2026,  0.0562, -0.1339, -0.0277,  0.0940,\n",
      "        -0.0397,  0.0998, -0.0096, -0.0504, -0.1266,  0.0529, -0.0065, -0.0421,\n",
      "        -0.1613, -0.1036,  0.0413, -0.1035,  0.0032,  0.1689,  0.0485,  0.0773,\n",
      "         0.0421,  0.0869,  0.1642, -0.2338, -0.0700, -0.0171,  0.0859,  0.1754,\n",
      "        -0.0498, -0.0659, -0.2626, -0.3053, -0.1249,  0.3110, -0.2882,  0.1583,\n",
      "        -0.1290,  0.1530,  0.1997,  0.0978, -0.0706, -0.3306, -0.1232,  0.1099,\n",
      "        -0.0240,  0.2895, -0.1534,  0.0213,  0.0170, -0.0752,  0.2857, -0.1547,\n",
      "        -0.3040,  0.0814,  0.0462,  0.1052,  0.1497, -0.0568, -0.1524, -0.0669,\n",
      "        -0.0821, -0.0125,  0.2078,  0.0554, -0.1579, -0.0542, -0.1574,  0.0291,\n",
      "         0.0553,  0.1344,  0.1641,  0.1579,  0.1031,  0.1412, -0.0005,  0.1176,\n",
      "         0.1068,  0.0631, -0.1329, -0.0141,  0.0636,  0.0548, -0.1874, -0.0593,\n",
      "         0.0228,  0.0590,  0.1187,  0.1356, -0.0442,  0.0060,  0.1191, -0.0481,\n",
      "        -0.0060, -0.1548, -0.0073, -0.1284,  0.0955, -0.0268, -0.1960, -0.0413,\n",
      "        -0.2996, -0.0690, -0.1802, -0.0116,  0.1737, -0.1187, -0.0989,  0.3258,\n",
      "         0.0862,  0.2322, -0.1078, -0.2218,  0.2485, -0.0009,  0.0191, -0.1251,\n",
      "        -0.0698,  0.2945, -0.1167,  0.0587,  0.0518, -0.0687, -0.1334, -0.3887,\n",
      "        -0.1085,  0.0959, -0.0336,  0.0971,  0.0598, -0.0925,  0.1035, -0.1732,\n",
      "        -0.1699, -0.1430,  0.0708,  0.1265, -0.0209, -0.0285, -0.0116,  0.1048,\n",
      "         0.2179, -0.0606,  0.0327,  0.0549, -0.0709,  0.1233,  0.0513,  0.1000,\n",
      "         0.0544, -0.0087, -0.0886, -0.0331,  0.1621,  0.2634,  0.0480,  0.0492,\n",
      "         0.2967,  0.0538,  0.0062,  0.0198,  0.2476, -0.0665, -0.1171, -0.1010,\n",
      "        -0.0318,  0.1481, -0.2134, -0.0498, -0.1719, -0.0166, -0.0033,  0.0716,\n",
      "        -0.0304, -0.0574, -0.0699,  0.1704,  0.0970,  0.2067,  0.0025,  0.1013,\n",
      "         0.1973, -0.1624,  0.2692,  0.0127,  0.1413, -0.0159, -0.0107, -0.1448,\n",
      "         0.0621, -0.1280,  0.2457,  0.0627,  0.0642, -0.1074,  0.1373, -0.1001,\n",
      "         0.0818, -0.0089, -0.0901, -0.1467,  0.0096, -0.1027, -0.0255, -0.0531,\n",
      "        -0.0621,  0.0303,  0.1169, -0.0655, -0.0792,  0.1999, -0.0488, -0.2642])\n",
      "Dataset 3: FAKE tensor([ 0.1009,  0.0788,  0.0382,  0.0063, -0.2123, -0.0909, -0.0321,  0.1999,\n",
      "        -0.1074, -0.1885,  0.0526, -0.1033, -0.0224,  0.0623,  0.1904, -0.0155,\n",
      "        -0.0132, -0.2278, -0.0443,  0.1717, -0.0372, -0.1662, -0.0838, -0.1172,\n",
      "        -0.0121,  0.0156,  0.1051, -0.0240,  0.0571,  0.1015,  0.0572, -0.2297,\n",
      "         0.1509, -0.1821,  0.0231,  0.1465, -0.1878,  0.1515,  0.0934, -0.1884,\n",
      "         0.0961, -0.0897, -0.0291, -0.0252, -0.0375,  0.1011, -0.0507,  0.0163,\n",
      "         0.1364,  0.0939, -0.0869,  0.0057, -0.0117,  0.0982,  0.0075, -0.0248,\n",
      "         0.0161, -0.0095,  0.0657, -0.0175,  0.0220, -0.0908, -0.0803,  0.0934,\n",
      "         0.0556, -0.0838,  0.1179,  0.0294,  0.1997,  0.2416, -0.1829, -0.0594,\n",
      "         0.1639, -0.0521,  0.0523, -0.1275,  0.1193, -0.1553,  0.0014,  0.0584,\n",
      "        -0.0125,  0.0666,  0.0409, -0.1897,  0.0356,  0.1640,  0.1158, -0.0333,\n",
      "        -0.1521,  0.0268, -0.0489, -0.1760, -0.0626, -0.0742,  0.1164, -0.0207,\n",
      "         0.1887, -0.0149, -0.1887,  0.1601,  0.1047,  0.0936, -0.1638, -0.1710,\n",
      "         0.1676,  0.0819,  0.0581, -0.0148, -0.1514,  0.0610, -0.0707, -0.1021,\n",
      "         0.1187,  0.0641,  0.1433,  0.0744,  0.1462, -0.1074, -0.0884, -0.3389,\n",
      "         0.0395, -0.0262, -0.0582,  0.1081, -0.2012,  0.0045, -0.0894, -0.0941,\n",
      "        -0.0389,  0.1087,  0.0405,  0.1224, -0.1907, -0.1263,  0.0603,  0.0088,\n",
      "         0.1023,  0.0924, -0.0653, -0.0707,  0.0448,  0.0886, -0.0056, -0.0457,\n",
      "        -0.0473, -0.0777,  0.1453,  0.0788, -0.0248, -0.0819, -0.0943,  0.1308,\n",
      "        -0.1563, -0.1390, -0.0568,  0.0067, -0.0484,  0.1390,  0.0564,  0.0048,\n",
      "         0.0141,  0.1514, -0.0568,  0.0283,  0.0292,  0.0545, -0.0871,  0.3761,\n",
      "         0.1373, -0.0155,  0.0117, -0.1022, -0.1304,  0.2656,  0.0112, -0.1654,\n",
      "        -0.2407,  0.0868,  0.0997, -0.0207, -0.0814,  0.0298, -0.0007, -0.1936,\n",
      "         0.0583,  0.1033,  0.0147, -0.0207,  0.1016,  0.0434, -0.0300, -0.1180,\n",
      "        -0.1374,  0.0896, -0.2858,  0.0825,  0.0486, -0.0539, -0.0577, -0.1894,\n",
      "         0.1541,  0.0902, -0.0229, -0.1351,  0.0560, -0.0957, -0.0700, -0.1760,\n",
      "         0.0532,  0.0126,  0.0122,  0.0862, -0.1120, -0.1469, -0.0924,  0.0904,\n",
      "        -0.0188,  0.0777,  0.0391,  0.0197, -0.0031,  0.0678,  0.0754,  0.0241,\n",
      "        -0.0226, -0.0565,  0.0043, -0.1144,  0.2086,  0.1990,  0.3136,  0.0547,\n",
      "         0.1680, -0.1078,  0.1213,  0.0505,  0.1769, -0.1051, -0.1023,  0.2016,\n",
      "         0.0718, -0.0475,  0.1084,  0.1281, -0.0287, -0.0648, -0.0325,  0.0494,\n",
      "         0.1566, -0.0712,  0.1146, -0.3255, -0.2393,  0.0668, -0.0483, -0.2030])\n",
      "Dataset 4: FAKE tensor([-0.1101, -0.0062, -0.0650,  0.0300, -0.1767, -0.1026,  0.0206,  0.0329,\n",
      "        -0.0224,  0.1554,  0.2560,  0.0042, -0.0410,  0.1706, -0.1502,  0.0886,\n",
      "        -0.1520,  0.0050, -0.1093, -0.1057,  0.1080, -0.0007,  0.0094, -0.0183,\n",
      "        -0.2599,  0.0592,  0.1233,  0.0105,  0.0129, -0.0295, -0.0515,  0.0981,\n",
      "        -0.0836,  0.0617, -0.0700, -0.0771, -0.0713, -0.1665, -0.0038,  0.0626,\n",
      "        -0.0311,  0.0804, -0.1489, -0.1697,  0.1625, -0.1202,  0.0369, -0.0038,\n",
      "         0.0409,  0.3061, -0.0049, -0.0074, -0.0681, -0.1979, -0.2345,  0.0849,\n",
      "        -0.0221, -0.0541,  0.0459, -0.0640, -0.1291, -0.0938,  0.0044,  0.1395,\n",
      "        -0.0425, -0.1157,  0.1687, -0.1059, -0.0410,  0.1127, -0.0465,  0.0341,\n",
      "         0.0699, -0.1193, -0.3327,  0.1118, -0.2333, -0.0132,  0.0754, -0.1218,\n",
      "        -0.0702, -0.0075, -0.0364, -0.0207,  0.0672, -0.0161, -0.1859, -0.0547,\n",
      "        -0.0153,  0.0160, -0.1566, -0.1648, -0.0006,  0.0845,  0.0480, -0.0952,\n",
      "        -0.0162, -0.0147,  0.0485, -0.1044, -0.0902,  0.0437,  0.0514,  0.0745,\n",
      "        -0.1332,  0.0531,  0.1154,  0.0614, -0.1901, -0.0737, -0.0476, -0.1373,\n",
      "        -0.0239,  0.0259, -0.1572, -0.0452,  0.0069,  0.2331, -0.0501,  0.0426,\n",
      "         0.2107, -0.0916, -0.0399, -0.1369, -0.0027,  0.1187,  0.0212,  0.0315,\n",
      "         0.1043, -0.0797, -0.0631, -0.0620,  0.0354, -0.0616, -0.1208,  0.0721,\n",
      "         0.1601,  0.1452, -0.0181, -0.0306, -0.0029, -0.0913,  0.0559,  0.2073,\n",
      "         0.0102, -0.0215, -0.1944, -0.1310, -0.0293, -0.0140, -0.1590,  0.0288,\n",
      "         0.0898, -0.1238, -0.0583, -0.1305, -0.0088,  0.0887,  0.1441, -0.0695,\n",
      "        -0.0421,  0.0131, -0.0105,  0.0676,  0.0906, -0.0886, -0.0588,  0.1310,\n",
      "         0.0665,  0.0448,  0.0207, -0.0108, -0.0989,  0.0439, -0.0881, -0.0491,\n",
      "         0.1482,  0.0648, -0.1962,  0.1071, -0.0061,  0.1234,  0.0978,  0.1744,\n",
      "        -0.0081, -0.0251, -0.1676, -0.0440,  0.0041, -0.0591,  0.1222,  0.0836,\n",
      "        -0.1080, -0.1393, -0.0222,  0.0201,  0.0772, -0.1044,  0.0311, -0.0889,\n",
      "        -0.2376, -0.1352, -0.0653,  0.2243, -0.0121,  0.0911, -0.0328, -0.0202,\n",
      "        -0.1326, -0.0229,  0.0326, -0.0224,  0.0663,  0.0278,  0.0497,  0.0807,\n",
      "        -0.1284,  0.0811,  0.1130,  0.2603,  0.1224, -0.0080,  0.1143, -0.0786,\n",
      "        -0.0999,  0.2226, -0.0777,  0.1109, -0.1332,  0.0775,  0.0275, -0.0325,\n",
      "        -0.0885,  0.0175,  0.1117, -0.2182, -0.1160,  0.0913,  0.1262, -0.1835,\n",
      "        -0.0802, -0.0741,  0.1413,  0.0576, -0.0098, -0.0429, -0.0405,  0.0087,\n",
      "        -0.1150,  0.0458,  0.0506,  0.0165, -0.1428, -0.1777,  0.1246,  0.1364])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:19.572938Z",
     "start_time": "2024-07-04T20:28:19.563184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset, index in zip(valid_dataset, range(5)):\n",
    "    print(f\"Dataset {index}: {'FAKE' if dataset[1] == torch.tensor([0]) else 'REAL'}\", dataset[0])"
   ],
   "id": "6ef836d6cfa4590f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0: REAL tensor([ 0.0724, -0.1702,  0.0588, -0.0646, -0.0232,  0.0529,  0.0260, -0.0317,\n",
      "         0.0384,  0.0115,  0.0973, -0.1264, -0.1521,  0.0985, -0.1118, -0.1622,\n",
      "        -0.0021, -0.1185, -0.0803,  0.1039,  0.0132, -0.0267,  0.0188, -0.0915,\n",
      "         0.0882, -0.0660, -0.0154, -0.0652, -0.0497,  0.2414, -0.0733, -0.0123,\n",
      "        -0.1224, -0.0921,  0.1879, -0.0109, -0.0182,  0.0160,  0.1230,  0.0801,\n",
      "         0.0036,  0.0912, -0.0067, -0.0827,  0.0433,  0.0309,  0.0245,  0.0412,\n",
      "        -0.0136, -0.0418, -0.0161,  0.1403, -0.0064, -0.0755, -0.0824,  0.0289,\n",
      "        -0.2233, -0.0769,  0.0059, -0.0435, -0.0988,  0.0930, -0.0204,  0.0090,\n",
      "        -0.0963,  0.1296,  0.1252,  0.0526,  0.0266,  0.0555, -0.0423, -0.0080,\n",
      "         0.0532, -0.0445, -0.1370,  0.0151, -0.0973,  0.0818, -0.0098, -0.0076,\n",
      "        -0.1265,  0.2511, -0.0711,  0.0671,  0.0637,  0.0328,  0.0781, -0.0059,\n",
      "         0.0129,  0.1937, -0.0829, -0.0067, -0.1427,  0.0659,  0.0203,  0.0583,\n",
      "        -0.0811, -0.0144, -0.0876, -0.0831, -0.0259, -0.0326, -0.0198,  0.0258,\n",
      "         0.0390, -0.1034, -0.1177, -0.0060, -0.1182,  0.0382, -0.0528, -0.0560,\n",
      "        -0.0539,  0.0034,  0.0875,  0.0891, -0.0211,  0.0242,  0.1108, -0.0052,\n",
      "        -0.0155,  0.0723, -0.0528, -0.0828,  0.0611, -0.0254,  0.0345, -0.1302,\n",
      "        -0.0046,  0.0551,  0.1061,  0.1925,  0.0693, -0.0259, -0.0394, -0.0929,\n",
      "         0.0023, -0.0781, -0.0515, -0.1501,  0.0863, -0.1015,  0.0009, -0.0913,\n",
      "         0.0875, -0.0492, -0.0294, -0.0513,  0.0981, -0.0094, -0.0093,  0.1357,\n",
      "         0.1152,  0.0504, -0.0655, -0.0521,  0.1467, -0.0521, -0.0098, -0.0185,\n",
      "        -0.1018, -0.0523, -0.0067, -0.1079,  0.0014,  0.0835,  0.0894,  0.0468,\n",
      "         0.0045, -0.0767, -0.0298,  0.0345,  0.0424,  0.0029, -0.0728, -0.0453,\n",
      "         0.0484,  0.0912, -0.2155,  0.0338, -0.0945, -0.0566,  0.0683,  0.0017,\n",
      "        -0.1650,  0.0598,  0.0692, -0.0004, -0.0944,  0.0428, -0.0636, -0.0422,\n",
      "         0.1107,  0.1030,  0.0195,  0.1045, -0.1021,  0.1772,  0.0313,  0.1053,\n",
      "         0.1536,  0.0972,  0.0345,  0.0538,  0.1343,  0.1005, -0.0443,  0.0243,\n",
      "        -0.0131, -0.0296, -0.0189, -0.1698,  0.0106,  0.0630, -0.0095, -0.0392,\n",
      "         0.1002, -0.0058,  0.1169,  0.0519, -0.0772,  0.0274,  0.0281, -0.0426,\n",
      "        -0.0320,  0.0853,  0.1361,  0.0206,  0.0440, -0.1293,  0.0685, -0.0343,\n",
      "         0.0153, -0.0864, -0.1321,  0.0309,  0.1113,  0.0347, -0.0531,  0.0033,\n",
      "        -0.0125,  0.0375,  0.0066, -0.0402,  0.0568,  0.0874,  0.1416, -0.0519,\n",
      "        -0.0553, -0.0560,  0.0353,  0.1680, -0.1025,  0.0158,  0.0441, -0.0535])\n",
      "Dataset 1: FAKE tensor([-0.0350,  0.0629,  0.0757,  0.0708, -0.0283, -0.0261,  0.1233, -0.0020,\n",
      "         0.1085,  0.0197,  0.0341, -0.1025, -0.0008, -0.0108, -0.0237,  0.1623,\n",
      "        -0.0057,  0.2385,  0.1444, -0.0157, -0.0705, -0.2362, -0.0308,  0.2146,\n",
      "        -0.0338, -0.0300, -0.0475,  0.0719,  0.0480, -0.0736, -0.1788, -0.0585,\n",
      "         0.0121, -0.0592, -0.0665,  0.2237,  0.1087, -0.1686,  0.1607,  0.1062,\n",
      "        -0.0270,  0.0237, -0.0947,  0.0897, -0.0383,  0.0459,  0.0732,  0.0751,\n",
      "        -0.2165,  0.1879, -0.2104,  0.1614, -0.0005,  0.0684, -0.0591, -0.1427,\n",
      "         0.1608, -0.1554,  0.1463,  0.0337,  0.1246,  0.0232,  0.1932, -0.0511,\n",
      "        -0.1202,  0.0519,  0.0840,  0.1857, -0.1231, -0.0871,  0.0428,  0.1725,\n",
      "        -0.2659,  0.0137, -0.0101,  0.0990,  0.0927,  0.0281, -0.2497,  0.0377,\n",
      "        -0.0161,  0.2716,  0.0314,  0.2324,  0.0945, -0.1119,  0.0208,  0.1666,\n",
      "        -0.0855, -0.1633, -0.0295, -0.1851,  0.2000,  0.0051,  0.1150, -0.1403,\n",
      "        -0.0746, -0.1444, -0.0600,  0.0949,  0.2250, -0.0674,  0.0092, -0.1404,\n",
      "        -0.1091,  0.1445, -0.0371, -0.0786,  0.1007,  0.1352,  0.1604, -0.0198,\n",
      "         0.1457, -0.1049,  0.1911,  0.0844,  0.2815,  0.0140,  0.0172, -0.1745,\n",
      "         0.0185, -0.2073, -0.0534,  0.0367,  0.0531, -0.0081, -0.0921, -0.2038,\n",
      "         0.1329,  0.1669, -0.1250,  0.1757, -0.0008, -0.0782, -0.0474, -0.0773,\n",
      "        -0.0375,  0.2554,  0.0613,  0.1088, -0.0095,  0.0472,  0.0054,  0.0128,\n",
      "        -0.1015, -0.0368, -0.0216,  0.0408, -0.1529, -0.1194, -0.0939,  0.0502,\n",
      "        -0.0886, -0.0540, -0.1297, -0.0089,  0.0806,  0.0013,  0.2570, -0.0110,\n",
      "         0.0175,  0.1003, -0.0671, -0.0448, -0.0794,  0.0135, -0.1032,  0.0690,\n",
      "         0.0379,  0.0311,  0.0015,  0.0217, -0.0879,  0.0673, -0.1220,  0.1192,\n",
      "         0.0267, -0.0838,  0.0680, -0.0739, -0.0014, -0.0684, -0.0685, -0.0368,\n",
      "         0.1196,  0.0782, -0.0972, -0.1493,  0.1174,  0.0676,  0.0963,  0.0945,\n",
      "        -0.0336,  0.0356, -0.0129,  0.1563,  0.0951,  0.1332, -0.0908,  0.0643,\n",
      "         0.0449,  0.0711,  0.1010, -0.1293,  0.0650, -0.2291, -0.1136, -0.2150,\n",
      "        -0.1716,  0.2944,  0.0083,  0.0205, -0.1455,  0.0006, -0.0068,  0.1046,\n",
      "         0.0067,  0.0065,  0.0548, -0.1984, -0.0134,  0.1971,  0.0204, -0.2845,\n",
      "        -0.0575,  0.1008,  0.0070, -0.0118,  0.0692,  0.0660,  0.1326, -0.0915,\n",
      "        -0.0505,  0.0492,  0.0987,  0.0011,  0.1675, -0.1221,  0.0259, -0.0179,\n",
      "         0.0207, -0.2252, -0.0854, -0.2694,  0.0899, -0.1108,  0.2000,  0.0464,\n",
      "         0.0028,  0.1433,  0.0926, -0.0833,  0.2183, -0.0042, -0.1248, -0.1461])\n",
      "Dataset 2: REAL tensor([ 1.9111e-02,  1.3312e-01,  3.8573e-02, -2.8905e-02, -5.6965e-02,\n",
      "        -2.3382e-01, -1.3960e-01,  8.3127e-02,  3.0660e-01,  2.0407e-01,\n",
      "        -9.5541e-02, -5.5373e-02,  2.0637e-01,  1.2316e-01,  7.1575e-02,\n",
      "        -1.4695e-01,  2.2245e-02,  5.7467e-03,  1.0356e-01,  1.5889e-01,\n",
      "         2.8479e-02,  1.2565e-01, -2.2566e-01,  3.3265e-01,  7.9865e-02,\n",
      "         8.9414e-02, -6.8511e-02, -4.8284e-03, -2.8972e-02,  8.2845e-02,\n",
      "        -6.2680e-02,  1.3517e-01, -2.0292e-01, -8.3389e-02,  3.0241e-02,\n",
      "        -8.5483e-02,  1.2958e-01,  5.2376e-02, -2.5652e-01,  4.7461e-02,\n",
      "        -6.2391e-02, -7.7510e-02, -2.7646e-01,  2.8222e-01, -2.8260e-02,\n",
      "        -1.2766e-01, -2.8795e-02,  1.4737e-01,  2.9080e-02,  1.8953e-01,\n",
      "         6.5597e-02,  1.8270e-01,  2.6169e-02,  1.6693e-02,  9.0737e-03,\n",
      "         1.5894e-01, -1.4346e-01,  5.4748e-03, -9.9500e-02,  6.3479e-02,\n",
      "         2.3904e-02, -1.4001e-02, -2.0097e-01, -4.7555e-02,  1.6258e-01,\n",
      "        -1.0478e-02,  9.1534e-02, -2.7555e-01, -5.2913e-02, -3.1919e-02,\n",
      "         1.1897e-01,  1.8530e-01, -2.1121e-03, -1.5545e-01, -2.5489e-01,\n",
      "        -2.3870e-01, -9.4000e-02,  2.2811e-02, -1.6105e-01,  2.3758e-02,\n",
      "        -1.9589e-01,  1.6880e-02,  1.4275e-01,  2.4349e-01, -1.0089e-01,\n",
      "        -2.9633e-01, -1.3113e-01,  9.2016e-02, -1.8407e-01,  2.1856e-01,\n",
      "        -5.5088e-02,  1.5207e-01,  3.3023e-02, -1.3242e-01,  1.3804e-01,\n",
      "        -3.7022e-02, -2.0519e-01, -6.0571e-02, -8.4466e-02,  6.1360e-02,\n",
      "         1.6308e-01, -1.4937e-01, -1.8470e-01, -1.2407e-02, -2.1212e-01,\n",
      "         4.1766e-02,  1.2381e-01,  1.0556e-03, -6.0012e-02,  9.8097e-03,\n",
      "        -1.6030e-02, -1.2329e-02,  2.0454e-01,  8.6623e-02,  6.1271e-02,\n",
      "         2.2969e-01, -1.0467e-01,  1.7694e-01, -1.1490e-02,  1.4747e-01,\n",
      "         2.0222e-01,  1.8962e-01, -2.2993e-01,  8.8830e-02,  8.4336e-02,\n",
      "         4.8064e-02, -3.1669e-01, -3.9068e-02,  6.5214e-02,  1.9977e-01,\n",
      "         2.0538e-01,  3.2727e-01, -2.4297e-01,  9.2099e-02,  1.0028e-02,\n",
      "        -1.4628e-01, -8.8194e-02, -2.6072e-01,  5.5356e-02, -3.3124e-01,\n",
      "         1.6310e-01,  8.9069e-02,  3.4230e-03, -4.0504e-02, -7.9600e-02,\n",
      "        -1.8349e-01, -8.1136e-03, -1.6262e-01, -4.7968e-02, -5.2527e-03,\n",
      "         6.7010e-02,  2.5721e-01,  4.3776e-02,  2.5058e-01,  5.7037e-02,\n",
      "        -1.3419e-01,  2.4223e-01,  3.4469e-01, -8.1760e-03,  6.1752e-02,\n",
      "         5.9272e-02,  1.9135e-01, -2.0065e-01,  5.0638e-02,  6.1626e-02,\n",
      "        -3.0587e-02, -2.0507e-01, -3.1298e-01, -4.8730e-02,  1.1481e-01,\n",
      "        -9.6539e-02, -2.5188e-02,  6.8097e-02, -3.3501e-04,  6.8976e-02,\n",
      "        -1.4741e-01, -2.3235e-01,  1.7320e-01,  2.2520e-01,  1.7046e-01,\n",
      "        -2.5923e-02,  8.7360e-02, -1.8616e-02,  2.6572e-02,  1.3961e-01,\n",
      "        -2.7392e-02, -1.2362e-01,  8.3111e-02, -1.8566e-01, -5.7172e-02,\n",
      "         6.5132e-02, -7.0199e-02,  2.6173e-02,  2.6877e-02, -9.8836e-02,\n",
      "        -1.3072e-01,  1.1087e-01,  1.6012e-01,  5.9011e-02,  1.7909e-01,\n",
      "         2.5037e-01,  6.2884e-02,  5.4805e-02,  5.1899e-02,  1.3875e-01,\n",
      "        -6.4790e-02, -1.7711e-01,  1.5708e-01,  7.9601e-03,  8.5891e-02,\n",
      "        -4.8715e-02, -1.8169e-01, -1.8481e-01,  2.2086e-01, -5.5944e-02,\n",
      "         2.9229e-02, -1.1908e-03, -4.6688e-02, -4.5490e-02,  2.9805e-01,\n",
      "         1.6189e-01,  1.9735e-01, -6.8565e-02, -8.2029e-02,  5.4623e-02,\n",
      "        -9.6008e-02,  2.6742e-01,  5.1538e-02,  1.6918e-01,  3.1568e-02,\n",
      "        -6.1241e-02,  1.1846e-01,  1.6444e-01, -1.1114e-01,  4.1018e-02,\n",
      "         1.0998e-01,  6.6063e-02, -9.4433e-02,  3.1686e-03, -2.5141e-01,\n",
      "         2.1193e-02,  2.3935e-01,  1.0629e-03, -2.0195e-01,  3.4861e-02,\n",
      "         1.9036e-01,  6.5000e-02,  2.1603e-01,  4.4434e-02, -9.9397e-02,\n",
      "        -6.9433e-02, -1.1033e-01, -2.5223e-01,  3.3541e-02, -6.8448e-02,\n",
      "        -5.6510e-02])\n",
      "Dataset 3: REAL tensor([-3.6520e-02, -1.4758e-02, -1.1824e-01, -5.3948e-02,  4.9864e-02,\n",
      "        -1.2769e-01, -2.9480e-02,  3.7523e-02,  4.7301e-02, -4.6389e-02,\n",
      "        -6.3080e-02,  1.1005e-01,  3.9483e-02, -5.7590e-02, -6.3614e-04,\n",
      "         1.6955e-02,  4.3735e-02,  4.4491e-03,  1.7113e-02, -1.1880e-02,\n",
      "        -1.2467e-01, -1.6733e-01, -2.5162e-02,  6.6958e-02, -1.0272e-02,\n",
      "        -1.1709e-01, -1.1885e-01,  6.5371e-02,  1.7425e-01,  4.7594e-02,\n",
      "         1.6551e-01,  3.7855e-02, -6.0114e-02, -1.3827e-01, -5.6918e-02,\n",
      "         1.0670e-01, -7.9216e-02, -1.0491e-01, -2.3805e-01,  8.3251e-03,\n",
      "         1.3263e-01, -9.5481e-02, -1.7719e-02, -1.6073e-01,  9.8186e-02,\n",
      "         5.8050e-02,  2.7620e-02,  4.0502e-02, -1.5563e-02,  1.2838e-01,\n",
      "         7.8628e-02,  9.2504e-03, -1.6748e-01,  1.1566e-01, -4.8483e-02,\n",
      "         1.2041e-01,  9.5760e-02,  2.2024e-02, -3.4612e-02,  2.7524e-01,\n",
      "         5.1966e-02,  1.5540e-01,  1.6028e-02, -2.8151e-02, -1.4496e-01,\n",
      "         1.5878e-01,  3.0849e-02,  2.7174e-02, -3.9080e-01, -1.5895e-01,\n",
      "         5.5650e-02,  4.8934e-02, -1.6669e-02,  6.3157e-02,  1.3993e-01,\n",
      "         2.2084e-01,  5.4679e-03,  6.5060e-02, -1.3698e-01,  1.1726e-01,\n",
      "        -1.4805e-02, -2.3146e-03, -1.4485e-01, -1.6527e-01,  9.2958e-02,\n",
      "        -1.8054e-01, -9.6869e-02,  1.7680e-01, -1.7547e-01,  1.8482e-02,\n",
      "         1.9951e-01,  1.6712e-01, -1.8699e-01, -1.0674e-01,  9.4269e-03,\n",
      "         2.0161e-02, -2.4928e-02, -4.7836e-02,  3.3999e-02,  1.4159e-02,\n",
      "         1.4313e-01, -1.0054e-01, -1.5549e-01, -2.0638e-01,  3.0042e-02,\n",
      "         4.9767e-02, -1.5346e-01,  9.4757e-02,  1.5062e-03, -1.1494e-01,\n",
      "         1.5666e-02, -1.4513e-02, -8.9630e-02, -4.1079e-02,  9.4702e-02,\n",
      "        -1.3350e-01,  6.9899e-02,  9.0087e-03, -1.1774e-01, -2.3389e-01,\n",
      "        -3.1758e-02,  2.7115e-02,  2.4665e-02,  5.7448e-02,  2.5012e-02,\n",
      "        -7.5525e-02, -3.2905e-02, -1.7550e-01, -1.4585e-01, -6.9645e-02,\n",
      "         1.5432e-01,  2.0123e-01,  2.3330e-03,  1.7362e-01,  2.9546e-02,\n",
      "        -5.1876e-02, -2.6323e-01,  1.1526e-01,  1.8513e-02, -1.4465e-01,\n",
      "        -5.9294e-02, -1.0277e-01,  4.6279e-02,  3.8605e-02, -6.7451e-02,\n",
      "         4.5734e-03,  1.3799e-01,  3.6589e-02,  1.0459e-01, -2.5704e-04,\n",
      "        -1.2343e-01,  1.3886e-01,  4.8290e-02, -9.5882e-02, -1.3953e-01,\n",
      "         1.9862e-01,  5.3242e-02, -1.0555e-01, -2.5655e-03,  6.2776e-02,\n",
      "        -6.2066e-02, -1.1184e-01,  1.1914e-01,  3.1240e-02, -1.1893e-01,\n",
      "         1.2010e-01, -9.5578e-02, -2.1526e-02,  5.0017e-02, -1.3283e-01,\n",
      "         1.0310e-01, -1.4745e-02, -1.2447e-01,  1.5872e-01, -8.6659e-02,\n",
      "         1.1784e-02,  1.3233e-01, -7.2358e-02, -6.0957e-02, -5.1518e-02,\n",
      "        -1.5012e-01,  2.3478e-01, -1.1730e-01,  1.1373e-01, -6.2591e-02,\n",
      "         1.0320e-01, -4.2056e-02, -6.0927e-02, -2.5581e-01, -4.4168e-02,\n",
      "         1.4263e-01,  5.8727e-02, -5.2775e-02, -2.6472e-02,  2.1500e-02,\n",
      "        -1.8913e-02,  1.8462e-02,  5.3025e-02,  2.3097e-02, -2.4917e-02,\n",
      "         2.8895e-01,  8.9501e-02,  5.5921e-03,  2.6293e-02, -5.1645e-02,\n",
      "        -2.4567e-02, -6.9070e-02, -8.1733e-03, -1.8582e-01,  5.3333e-02,\n",
      "         1.3853e-01,  4.6288e-02, -1.8938e-02,  7.0412e-02, -4.7773e-04,\n",
      "         8.6806e-02, -1.1945e-02,  5.3122e-02,  1.4790e-01, -1.8482e-02,\n",
      "        -5.7280e-02, -4.7583e-02,  2.9489e-02,  4.8438e-02,  9.9737e-02,\n",
      "        -4.2256e-02,  8.0422e-03,  4.1946e-02, -2.9371e-01, -1.0545e-01,\n",
      "        -1.3475e-01, -1.3673e-01,  4.2835e-02, -1.6899e-01,  1.1251e-01,\n",
      "         2.3472e-01, -3.8666e-02, -7.9837e-02, -2.4885e-02,  6.9786e-02,\n",
      "         1.1190e-01,  3.6094e-02,  1.8420e-02, -3.7577e-02,  1.1092e-02,\n",
      "        -1.4193e-02,  1.5974e-01, -6.1582e-02,  1.0113e-01, -1.5820e-01,\n",
      "         8.5717e-03,  4.9152e-02,  1.1998e-01,  6.6842e-02, -1.5594e-02,\n",
      "         5.0251e-03])\n",
      "Dataset 4: FAKE tensor([ 0.1188,  0.0384, -0.0630, -0.0038, -0.1759, -0.1651,  0.1295, -0.0069,\n",
      "        -0.1423,  0.0937,  0.2020,  0.0947,  0.0770,  0.0164,  0.0022,  0.1678,\n",
      "        -0.1554, -0.0152, -0.0870, -0.0766,  0.1764,  0.0303, -0.0499, -0.0952,\n",
      "        -0.0954, -0.1683,  0.0484, -0.0629,  0.0380, -0.0718,  0.0121,  0.1227,\n",
      "        -0.1021, -0.0032,  0.0184, -0.0042,  0.1193, -0.2051, -0.0519,  0.0788,\n",
      "         0.0113,  0.1380, -0.0903, -0.1438,  0.0951, -0.1713,  0.0534, -0.1346,\n",
      "         0.0528,  0.2625,  0.0767, -0.0745,  0.0196,  0.0007, -0.1945,  0.0623,\n",
      "         0.0349, -0.1234,  0.0620, -0.1499, -0.0388,  0.0085,  0.0718,  0.0890,\n",
      "        -0.1758,  0.1562,  0.1119, -0.0978,  0.0724,  0.1202, -0.0130, -0.0784,\n",
      "         0.0840,  0.0069, -0.3251,  0.0542, -0.0860, -0.1254, -0.0688,  0.0213,\n",
      "        -0.0758,  0.0161, -0.0230,  0.0405,  0.1030, -0.0766, -0.1500, -0.0732,\n",
      "        -0.0692,  0.1457, -0.0902, -0.1106, -0.0294,  0.0409,  0.0431, -0.0087,\n",
      "        -0.0554, -0.1235, -0.1268,  0.0809, -0.0106, -0.0779, -0.0423,  0.0094,\n",
      "        -0.1149,  0.0234, -0.0004,  0.0943, -0.1497, -0.0892,  0.1056,  0.0126,\n",
      "        -0.0481, -0.1298, -0.1202,  0.0664,  0.0093,  0.1335,  0.0257,  0.0095,\n",
      "         0.1580,  0.0789, -0.1674,  0.0908, -0.1243,  0.1207, -0.0931,  0.1645,\n",
      "         0.0761,  0.0283,  0.0015, -0.1120,  0.0231, -0.0527, -0.0283,  0.0620,\n",
      "        -0.0228,  0.2745, -0.0008, -0.0520, -0.0249,  0.0830, -0.0731,  0.2123,\n",
      "         0.0317, -0.0262, -0.0851, -0.1248, -0.0477, -0.1660,  0.0148,  0.0774,\n",
      "         0.1006, -0.2009,  0.1191,  0.0588, -0.1777,  0.1528, -0.0250, -0.0618,\n",
      "        -0.0344, -0.0801,  0.0408,  0.0596,  0.0724,  0.1082,  0.0301,  0.1466,\n",
      "         0.0836, -0.0702, -0.0170, -0.0689, -0.1174,  0.0047, -0.0372,  0.0753,\n",
      "        -0.0103,  0.1087, -0.2132,  0.0178, -0.0928,  0.0746,  0.0559,  0.0963,\n",
      "         0.0947,  0.0113, -0.0692, -0.0724,  0.1151, -0.0867,  0.1199,  0.1546,\n",
      "        -0.0219,  0.0626,  0.0336, -0.0603, -0.0009,  0.0381, -0.0549,  0.0411,\n",
      "        -0.0111, -0.0392,  0.0461, -0.0537,  0.0930, -0.0512, -0.0184, -0.0630,\n",
      "        -0.0034, -0.0075, -0.0272, -0.0354, -0.0465,  0.0407,  0.1164,  0.1641,\n",
      "        -0.1945, -0.1720,  0.0911,  0.2230,  0.0185, -0.0348,  0.1210, -0.0807,\n",
      "        -0.2079,  0.1507, -0.2248,  0.1791, -0.1592,  0.0223,  0.2119, -0.1401,\n",
      "         0.0027,  0.0650,  0.1497, -0.0826, -0.0599, -0.0956,  0.1902, -0.1589,\n",
      "        -0.1673, -0.0387, -0.0036,  0.0598,  0.1400, -0.0469, -0.1211,  0.0340,\n",
      "        -0.0336,  0.0148,  0.0005,  0.0158, -0.0470, -0.1216, -0.0947,  0.1425])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:19.581157Z",
     "start_time": "2024-07-04T20:28:19.573944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset, index in zip(test_dataset, range(1)):\n",
    "    if test_dataset.multi_label:\n",
    "        print(f\"Dataset {index}-0:\", dataset[1][0], dataset[0][0])\n",
    "        print(f\"Dataset {index}-1:\", dataset[1][1], dataset[0][1])\n",
    "    else:\n",
    "        print(f\"Dataset {index}:\", dataset[0])"
   ],
   "id": "b4306aa86c180ad8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0-0: speech tensor([-9.3006e-02,  2.0858e-02,  2.1069e-02, -1.1293e-02, -8.1300e-03,\n",
      "        -1.6473e-01, -5.3140e-02, -9.4842e-02,  1.8247e-01, -4.9645e-03,\n",
      "         9.4941e-02, -8.9201e-02, -1.7526e-02,  5.7322e-02, -2.0652e-02,\n",
      "        -6.9793e-02, -1.5087e-01,  6.3277e-02,  2.8609e-02,  1.1608e-01,\n",
      "        -1.0370e-01, -5.3388e-02,  1.3286e-01,  9.9311e-02,  6.6260e-02,\n",
      "         4.8091e-02,  8.3858e-03,  9.4828e-02, -4.1591e-02, -1.2084e-02,\n",
      "         1.3298e-01,  2.7751e-02,  3.9478e-03, -1.7945e-02, -7.7472e-02,\n",
      "         8.5669e-02, -4.3482e-02, -4.9096e-02, -2.1974e-01, -3.1006e-02,\n",
      "         1.7944e-03, -1.9233e-01, -3.6963e-02,  1.3835e-01,  3.0929e-02,\n",
      "        -2.0693e-01, -6.7273e-02, -3.4093e-02,  1.7037e-02,  1.6843e-01,\n",
      "         2.4608e-02,  1.3921e-02,  1.0036e-03,  8.1279e-02, -6.6403e-02,\n",
      "         2.9936e-02, -1.0958e-01, -3.3157e-02,  3.7874e-02,  1.0300e-02,\n",
      "         1.1396e-01,  1.1564e-02,  3.5110e-02, -4.3579e-03, -1.8605e-02,\n",
      "         1.6384e-02, -4.0687e-02, -3.0982e-02, -9.8731e-02,  1.1089e-01,\n",
      "        -1.7942e-02,  1.4703e-01, -2.4255e-02, -6.6287e-02, -1.3206e-01,\n",
      "        -9.0260e-02, -7.5278e-02,  4.9493e-02, -8.5588e-02, -4.0829e-02,\n",
      "        -7.5792e-02, -9.2861e-02, -8.3082e-02,  1.9261e-01, -8.5264e-02,\n",
      "        -2.5739e-01, -7.4183e-02, -1.5667e-02, -2.4651e-05,  5.7345e-02,\n",
      "        -5.8038e-03, -9.2006e-03,  1.2883e-01, -3.9572e-02,  1.8163e-01,\n",
      "         2.8047e-02, -7.5681e-02,  1.3049e-02,  1.0366e-02, -1.0147e-01,\n",
      "         1.0788e-01,  4.7085e-03, -7.6386e-02, -2.8073e-03, -2.2430e-01,\n",
      "         1.1901e-01,  1.1610e-01, -6.2558e-02,  6.5849e-02,  1.0328e-02,\n",
      "        -1.3762e-01,  2.8312e-02,  9.4190e-02,  5.4033e-02,  4.3953e-02,\n",
      "         3.9558e-02, -8.7822e-02,  1.4310e-01, -7.8826e-02,  1.4287e-01,\n",
      "         1.4129e-01,  8.1583e-02, -7.3914e-02,  1.1194e-01,  1.0648e-01,\n",
      "        -5.3453e-02, -1.2659e-01, -8.7730e-02,  1.2092e-01,  7.9945e-02,\n",
      "         5.0125e-02, -3.0873e-02, -6.2004e-02,  5.9145e-03,  1.1289e-01,\n",
      "         4.0801e-03,  1.2986e-01, -1.9314e-01,  1.6427e-01, -1.5056e-01,\n",
      "         1.3008e-02, -5.0763e-03, -1.4052e-01,  3.9319e-02, -1.5015e-01,\n",
      "        -2.7561e-02,  1.1278e-02, -4.4794e-02,  5.0733e-02, -6.1986e-02,\n",
      "        -8.5518e-02,  1.0698e-01,  1.5005e-02,  4.9034e-02,  1.5217e-01,\n",
      "        -1.5141e-01,  1.7286e-01,  1.4041e-01, -1.4990e-03, -3.2972e-02,\n",
      "         1.7415e-02,  1.3198e-01, -1.9676e-01, -5.3502e-02, -5.8997e-03,\n",
      "        -9.0525e-02, -1.4596e-01,  9.2391e-02,  6.9465e-02, -3.2674e-02,\n",
      "        -6.1388e-02,  3.2864e-02, -3.6897e-02, -1.4535e-01,  2.3025e-02,\n",
      "        -2.6530e-02, -8.5780e-02,  5.6487e-02, -5.7165e-02,  1.0546e-01,\n",
      "         9.6161e-03, -7.6080e-02,  5.2815e-02,  1.5985e-02,  4.1462e-02,\n",
      "         1.6009e-01, -3.9107e-02, -1.6361e-02, -1.7737e-01,  8.1966e-02,\n",
      "         1.2584e-01, -1.4209e-02,  6.8055e-02, -7.3635e-03, -1.0546e-01,\n",
      "        -9.0805e-02,  1.9969e-01,  1.1650e-01,  3.5574e-02,  1.2130e-01,\n",
      "         2.4041e-01,  8.5336e-02,  1.1375e-02, -3.9290e-02, -4.7224e-02,\n",
      "        -7.0151e-02, -1.3555e-02,  3.7655e-02, -4.5989e-02,  1.4474e-01,\n",
      "         9.1241e-03,  1.2774e-01,  2.4790e-02,  5.9695e-02,  6.1726e-02,\n",
      "         1.8009e-02, -1.0001e-01,  2.4238e-02, -1.6092e-02, -2.9058e-02,\n",
      "         2.9087e-02,  3.0294e-04, -7.4143e-02,  5.4801e-02,  7.7352e-02,\n",
      "        -1.8573e-01,  2.2645e-01, -7.0137e-02, -3.3181e-02,  6.5429e-02,\n",
      "         7.9157e-02, -4.7564e-02, -7.8253e-02,  6.6375e-02, -9.7843e-02,\n",
      "        -2.6054e-02, -4.0974e-02, -1.6512e-01, -4.6891e-02,  1.0787e-03,\n",
      "         9.3564e-03,  1.3000e-01, -1.3463e-03, -5.5436e-03,  3.1123e-02,\n",
      "         6.6507e-02, -6.6288e-03,  1.8772e-02,  2.3949e-02, -3.5668e-02,\n",
      "        -2.4739e-02, -2.7429e-02, -3.1188e-02,  1.1169e-01, -5.4416e-02,\n",
      "        -1.7206e-01])\n",
      "Dataset 0-1: speech tensor([ 0.0193,  0.0070,  0.0318, -0.0644, -0.0267, -0.1003,  0.0016, -0.0492,\n",
      "         0.1325, -0.0359,  0.0967, -0.1722,  0.0178,  0.0627, -0.0060, -0.0863,\n",
      "        -0.0732,  0.0616,  0.0352,  0.0844, -0.1218,  0.0173,  0.0795,  0.0184,\n",
      "         0.0282,  0.0634,  0.0291,  0.0721, -0.0514, -0.0366,  0.0175, -0.0113,\n",
      "         0.0036,  0.0237, -0.1331,  0.1083,  0.0145,  0.0371, -0.1068,  0.0565,\n",
      "        -0.0658, -0.0366,  0.0192,  0.1124,  0.0970, -0.1660, -0.0554, -0.0350,\n",
      "        -0.0774,  0.0018,  0.0347,  0.1037, -0.0006, -0.0662, -0.0069, -0.0715,\n",
      "        -0.0621, -0.0412,  0.1115,  0.0573,  0.1526, -0.0170,  0.0640,  0.0368,\n",
      "        -0.0594, -0.0736, -0.0426,  0.0202, -0.0310,  0.1532, -0.0325,  0.0826,\n",
      "        -0.0317, -0.0200, -0.1198, -0.1314, -0.0734, -0.0129, -0.1617,  0.0054,\n",
      "         0.0336, -0.0444, -0.0704,  0.0205, -0.0994, -0.1783, -0.0339, -0.0256,\n",
      "        -0.0383,  0.0003, -0.0051, -0.0249,  0.0260, -0.0112,  0.1318, -0.0181,\n",
      "        -0.0263, -0.0243,  0.0944, -0.0482,  0.0239,  0.0004, -0.0482,  0.0234,\n",
      "        -0.0965,  0.1114,  0.0717,  0.0022,  0.0388, -0.0594, -0.0949, -0.0438,\n",
      "        -0.0230, -0.0963, -0.0502,  0.0862,  0.0136,  0.0117, -0.1462,  0.0566,\n",
      "         0.1148,  0.0488, -0.0729,  0.0773,  0.0419, -0.1291, -0.0615, -0.0584,\n",
      "         0.0631,  0.0643,  0.0875,  0.0492, -0.0134,  0.0336, -0.0091, -0.0576,\n",
      "         0.1535,  0.0105,  0.2289, -0.1201, -0.0275, -0.0532,  0.0091, -0.0615,\n",
      "        -0.0382,  0.0508, -0.0298, -0.0203,  0.0144, -0.0990, -0.0331,  0.0033,\n",
      "         0.0765,  0.0432, -0.0315,  0.0053,  0.0976,  0.0768,  0.0074, -0.0762,\n",
      "         0.0712,  0.0574, -0.1195,  0.0138, -0.0209, -0.0543, -0.0799,  0.1565,\n",
      "         0.0737, -0.0016, -0.0368, -0.0142, -0.0877, -0.2142,  0.0808, -0.0574,\n",
      "        -0.0449,  0.0201, -0.0786,  0.1637,  0.0866, -0.0604, -0.0499, -0.0317,\n",
      "         0.0365,  0.1282,  0.0436,  0.0901, -0.0207,  0.0079,  0.0089,  0.0684,\n",
      "         0.0667,  0.0360, -0.1040, -0.0848,  0.1783,  0.0750, -0.0253,  0.0414,\n",
      "         0.1592, -0.0105, -0.0127, -0.0608,  0.0233, -0.0517, -0.0235, -0.0385,\n",
      "        -0.0316,  0.0980, -0.0412, -0.0047,  0.0034, -0.0375,  0.0063, -0.0263,\n",
      "        -0.0715, -0.0328, -0.0210, -0.0040,  0.0915, -0.0102,  0.0151, -0.0064,\n",
      "         0.0587, -0.1434,  0.0470,  0.0527,  0.0412,  0.0930,  0.1425, -0.1146,\n",
      "        -0.0403,  0.0592,  0.0020,  0.0745,  0.0366, -0.1475, -0.0155,  0.1448,\n",
      "         0.0312,  0.0588,  0.0087, -0.0121, -0.0055,  0.0167,  0.0434,  0.0899,\n",
      "         0.0046, -0.0191,  0.0179, -0.0562, -0.0313, -0.0202,  0.0057, -0.0479])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:26.181157Z",
     "start_time": "2024-07-04T20:28:19.582166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 라벨 분리\n",
    "\n",
    "import copy\n",
    "\n",
    "real_dataset = copy.deepcopy(train_dataset)\n",
    "fake_dataset = copy.deepcopy(train_dataset)\n",
    "\n",
    "def data_filter(target):\n",
    "    def filter_data(ids, dataset, labels):\n",
    "        filtered = [(_id, data, label) for _id, data, label in zip(ids, dataset, labels) if label == target]\n",
    "        transposed = list(zip(*filtered))\n",
    "        return transposed\n",
    "    return filter_data\n",
    "\n",
    "real_dataset.transforms(transform=data_filter(torch.tensor([1])))\n",
    "fake_dataset.transforms(transform=data_filter(torch.tensor([0])))"
   ],
   "id": "bc707239b611a9d1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:26.194157Z",
     "start_time": "2024-07-04T20:28:26.182161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset, index in zip(real_dataset, range(5)):\n",
    "    print(f\"Dataset {index}: {'FAKE' if dataset[1] == torch.tensor([0]) else 'REAL'}\", dataset[0])"
   ],
   "id": "913d3c2274418754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0: REAL tensor([ 0.0529,  0.1010,  0.1172, -0.0631,  0.0632, -0.1159, -0.0335, -0.0172,\n",
      "         0.1637,  0.0391,  0.0796, -0.0766,  0.0501, -0.0188,  0.0757, -0.1223,\n",
      "        -0.2077,  0.0897,  0.1898,  0.1035, -0.0897, -0.2672,  0.0721,  0.2452,\n",
      "         0.2348,  0.2213, -0.0099,  0.1075,  0.0690, -0.2120,  0.0235,  0.0167,\n",
      "        -0.1776, -0.0702, -0.0985,  0.2446, -0.0017, -0.0182, -0.2660,  0.0888,\n",
      "         0.0833,  0.1668, -0.1144,  0.2026,  0.0562, -0.1339, -0.0277,  0.0940,\n",
      "        -0.0397,  0.0998, -0.0096, -0.0504, -0.1266,  0.0529, -0.0065, -0.0421,\n",
      "        -0.1613, -0.1036,  0.0413, -0.1035,  0.0032,  0.1689,  0.0485,  0.0773,\n",
      "         0.0421,  0.0869,  0.1642, -0.2338, -0.0700, -0.0171,  0.0859,  0.1754,\n",
      "        -0.0498, -0.0659, -0.2626, -0.3053, -0.1249,  0.3110, -0.2882,  0.1583,\n",
      "        -0.1290,  0.1530,  0.1997,  0.0978, -0.0706, -0.3306, -0.1232,  0.1099,\n",
      "        -0.0240,  0.2895, -0.1534,  0.0213,  0.0170, -0.0752,  0.2857, -0.1547,\n",
      "        -0.3040,  0.0814,  0.0462,  0.1052,  0.1497, -0.0568, -0.1524, -0.0669,\n",
      "        -0.0821, -0.0125,  0.2078,  0.0554, -0.1579, -0.0542, -0.1574,  0.0291,\n",
      "         0.0553,  0.1344,  0.1641,  0.1579,  0.1031,  0.1412, -0.0005,  0.1176,\n",
      "         0.1068,  0.0631, -0.1329, -0.0141,  0.0636,  0.0548, -0.1874, -0.0593,\n",
      "         0.0228,  0.0590,  0.1187,  0.1356, -0.0442,  0.0060,  0.1191, -0.0481,\n",
      "        -0.0060, -0.1548, -0.0073, -0.1284,  0.0955, -0.0268, -0.1960, -0.0413,\n",
      "        -0.2996, -0.0690, -0.1802, -0.0116,  0.1737, -0.1187, -0.0989,  0.3258,\n",
      "         0.0862,  0.2322, -0.1078, -0.2218,  0.2485, -0.0009,  0.0191, -0.1251,\n",
      "        -0.0698,  0.2945, -0.1167,  0.0587,  0.0518, -0.0687, -0.1334, -0.3887,\n",
      "        -0.1085,  0.0959, -0.0336,  0.0971,  0.0598, -0.0925,  0.1035, -0.1732,\n",
      "        -0.1699, -0.1430,  0.0708,  0.1265, -0.0209, -0.0285, -0.0116,  0.1048,\n",
      "         0.2179, -0.0606,  0.0327,  0.0549, -0.0709,  0.1233,  0.0513,  0.1000,\n",
      "         0.0544, -0.0087, -0.0886, -0.0331,  0.1621,  0.2634,  0.0480,  0.0492,\n",
      "         0.2967,  0.0538,  0.0062,  0.0198,  0.2476, -0.0665, -0.1171, -0.1010,\n",
      "        -0.0318,  0.1481, -0.2134, -0.0498, -0.1719, -0.0166, -0.0033,  0.0716,\n",
      "        -0.0304, -0.0574, -0.0699,  0.1704,  0.0970,  0.2067,  0.0025,  0.1013,\n",
      "         0.1973, -0.1624,  0.2692,  0.0127,  0.1413, -0.0159, -0.0107, -0.1448,\n",
      "         0.0621, -0.1280,  0.2457,  0.0627,  0.0642, -0.1074,  0.1373, -0.1001,\n",
      "         0.0818, -0.0089, -0.0901, -0.1467,  0.0096, -0.1027, -0.0255, -0.0531,\n",
      "        -0.0621,  0.0303,  0.1169, -0.0655, -0.0792,  0.1999, -0.0488, -0.2642])\n",
      "Dataset 1: REAL tensor([ 1.4364e-01,  9.0336e-02,  2.1308e-02,  7.6722e-03,  1.2504e-02,\n",
      "         7.5371e-02,  8.4349e-02, -5.1006e-02,  3.4444e-02, -2.3075e-01,\n",
      "         5.0798e-02, -1.5680e-01,  5.4791e-02, -7.6730e-02,  8.0138e-02,\n",
      "         7.8804e-02, -3.2141e-02,  3.8057e-02,  1.4054e-01,  7.2340e-02,\n",
      "        -2.1561e-01, -2.2676e-01, -2.8306e-01, -1.4788e-04, -3.0458e-02,\n",
      "         4.7489e-02, -2.3231e-01, -1.8333e-02, -1.3653e-03,  1.1318e-01,\n",
      "        -1.2433e-01, -2.1484e-01,  3.2989e-02, -2.1731e-02,  1.4232e-01,\n",
      "         7.6380e-02,  2.6390e-04, -9.8268e-02, -2.2276e-01, -2.5809e-02,\n",
      "         4.1046e-02, -3.6620e-02, -1.9219e-01, -1.3120e-01,  9.5776e-02,\n",
      "         1.0598e-01, -2.2736e-01,  7.2540e-02, -2.3036e-03,  3.1137e-03,\n",
      "        -9.6720e-02,  1.8875e-01,  1.2617e-01,  2.9984e-03, -3.8207e-03,\n",
      "         6.7233e-02,  2.9987e-02, -8.0391e-03, -2.5761e-02, -5.0867e-02,\n",
      "        -4.7638e-02, -5.9081e-02, -9.7828e-02, -2.1760e-01, -7.3739e-02,\n",
      "        -1.0089e-01,  1.3069e-01,  9.5878e-02, -5.2956e-02,  2.2170e-01,\n",
      "         1.8427e-04,  2.2085e-01, -1.2052e-01,  3.8071e-02, -1.2217e-02,\n",
      "        -1.9764e-01,  1.5467e-01,  1.3952e-01,  8.8448e-03,  1.2143e-02,\n",
      "         1.5100e-03,  1.7189e-01, -9.2352e-02,  7.2411e-03,  2.1575e-02,\n",
      "        -2.4320e-01, -6.4926e-02,  8.6033e-02, -1.0108e-01, -9.6224e-02,\n",
      "        -7.5491e-03, -1.7735e-02, -3.0717e-02, -1.1036e-01,  1.8681e-01,\n",
      "         1.5424e-01, -3.5974e-03, -2.3245e-01, -1.8142e-01, -4.8864e-02,\n",
      "         8.5887e-02, -1.6180e-01, -1.4497e-01,  5.7410e-02,  1.2061e-01,\n",
      "        -1.7931e-01, -8.4535e-02,  6.1335e-02, -2.4160e-01,  1.1029e-04,\n",
      "        -1.6582e-01, -1.0219e-01, -1.4339e-01, -3.9571e-02, -1.2684e-01,\n",
      "         2.1947e-01,  2.2986e-02,  1.6151e-02, -1.3943e-01, -2.1265e-01,\n",
      "         8.6204e-02, -7.1381e-03, -1.2969e-01,  2.5734e-02, -1.5005e-01,\n",
      "         6.2674e-03, -3.5354e-02,  2.0493e-01, -2.3003e-01, -3.4200e-03,\n",
      "        -8.8671e-02,  8.4059e-02,  5.2549e-02,  2.8162e-02, -2.1337e-01,\n",
      "        -2.3305e-01, -5.0913e-02,  1.7589e-01, -1.5423e-01, -2.8900e-01,\n",
      "        -5.8153e-02,  2.3145e-02, -5.3323e-02, -7.4590e-02,  6.5537e-02,\n",
      "        -1.6666e-01,  2.9406e-01, -4.9574e-02, -3.4651e-02, -8.1807e-02,\n",
      "        -1.1397e-01,  2.8302e-02, -7.9943e-02,  9.7389e-03,  9.6303e-02,\n",
      "         7.7697e-02, -8.7590e-03,  6.2318e-02,  1.1689e-01, -4.0494e-02,\n",
      "         1.0563e-04,  2.4383e-01, -1.6243e-01, -2.4026e-01,  1.3183e-01,\n",
      "         2.1370e-01, -3.3164e-01,  1.6864e-01,  5.8976e-02,  5.6501e-02,\n",
      "         1.0893e-01, -1.2630e-01, -9.3865e-02, -1.0700e-01,  1.2259e-01,\n",
      "        -1.1213e-01, -3.2357e-02,  1.1430e-01,  7.2554e-02, -1.6277e-02,\n",
      "        -9.1165e-02,  5.6522e-02, -1.0776e-01, -2.3285e-01,  5.6272e-02,\n",
      "         3.4747e-01,  2.5098e-02,  1.2502e-01, -7.8085e-02, -7.8167e-02,\n",
      "        -2.0958e-01,  1.7812e-02,  1.0403e-01, -1.8201e-02,  1.7984e-02,\n",
      "         5.9869e-02,  7.8346e-03, -1.4355e-01, -1.0313e-01,  1.4731e-02,\n",
      "         3.5615e-01,  1.6953e-01,  2.2384e-01,  1.4660e-01,  6.1071e-02,\n",
      "        -2.7892e-01,  3.5714e-02, -1.8204e-01,  1.2913e-01,  1.6586e-01,\n",
      "        -3.1726e-02, -1.4682e-01, -9.1796e-02,  1.1385e-01, -1.0794e-01,\n",
      "         3.0788e-01,  1.8443e-01,  4.7122e-02,  2.5994e-02,  1.3708e-01,\n",
      "        -5.9987e-02,  2.5355e-01,  5.6304e-02,  2.7589e-02, -1.2267e-01,\n",
      "         8.2891e-02,  3.8707e-02,  2.0046e-01,  3.0652e-01,  2.0848e-02,\n",
      "         1.7024e-02,  1.3366e-01,  1.3235e-01, -3.7860e-02,  5.2816e-02,\n",
      "        -1.8000e-02,  3.9259e-01,  5.6568e-02,  5.9167e-02, -4.6714e-02,\n",
      "         1.2934e-01,  5.9212e-02,  6.2305e-02, -1.5601e-02,  6.3878e-02,\n",
      "         3.6385e-02,  2.2695e-01, -4.2652e-02,  5.2906e-02,  3.1844e-02,\n",
      "        -6.9259e-02, -1.3233e-01, -9.3700e-02,  8.8365e-02, -6.7755e-02,\n",
      "        -1.3990e-01])\n",
      "Dataset 2: REAL tensor([ 4.9122e-03,  1.0484e-01,  7.1577e-02, -1.4469e-01,  1.7983e-01,\n",
      "         5.7676e-02,  1.1748e-01, -1.7480e-01,  3.7193e-02, -2.2340e-01,\n",
      "        -2.0783e-02, -1.3955e-02, -1.2162e-01, -3.6640e-01,  2.3986e-02,\n",
      "         2.9218e-01, -7.6108e-02,  4.1813e-03, -3.3101e-01,  1.6253e-02,\n",
      "        -8.5255e-02, -3.1954e-01,  2.0235e-01,  8.4071e-02, -7.1433e-02,\n",
      "        -2.0179e-02, -2.2634e-02, -3.5683e-02,  5.5590e-02,  1.7927e-01,\n",
      "        -4.4771e-02, -1.0728e-01,  1.7925e-01, -1.8636e-01,  8.0983e-02,\n",
      "         4.9999e-03,  1.1394e-01, -1.6526e-01, -1.8650e-01, -9.1285e-02,\n",
      "         1.0681e-01, -1.1021e-01, -1.2610e-01, -6.8658e-02,  1.1002e-01,\n",
      "         2.7023e-02, -1.8304e-01, -2.0624e-01, -3.0476e-02, -2.0750e-02,\n",
      "         6.2777e-02,  7.1534e-02,  7.6398e-02,  1.0974e-01,  8.5012e-02,\n",
      "        -7.6646e-02,  4.9519e-02,  1.4316e-01,  1.3923e-02, -3.9530e-02,\n",
      "         1.8139e-03,  6.2972e-02, -1.8317e-01,  1.7190e-01, -2.1132e-02,\n",
      "         4.0401e-02,  1.0070e-01,  8.6721e-02,  7.5304e-02, -1.4267e-01,\n",
      "         3.4191e-02,  2.2650e-01, -9.0205e-02, -1.9404e-01,  2.6482e-01,\n",
      "         4.1598e-04,  8.5843e-02, -2.9542e-03,  6.0361e-02, -1.1207e-01,\n",
      "         1.1315e-01, -1.2144e-01, -8.5686e-02, -1.5679e-01,  6.9204e-02,\n",
      "        -1.9776e-01, -7.4594e-02, -1.7235e-01,  6.8854e-03,  1.8682e-01,\n",
      "        -1.4288e-01,  5.5528e-02, -3.9052e-02, -1.6268e-01,  1.2712e-01,\n",
      "        -5.4389e-02, -1.2442e-01,  1.4179e-01,  1.4235e-02,  2.5162e-01,\n",
      "        -1.3284e-01,  7.2077e-02, -1.8510e-01, -3.5111e-01,  1.2118e-01,\n",
      "         1.6859e-01,  1.5867e-01,  1.4159e-01, -4.8433e-02,  1.9304e-01,\n",
      "         9.8077e-02,  1.8398e-01,  2.2106e-01, -6.5140e-02, -9.1983e-02,\n",
      "        -5.2030e-03, -8.3536e-03, -6.8474e-02,  1.2461e-01,  9.8895e-02,\n",
      "         1.0930e-01, -7.3721e-02, -1.8125e-01,  2.7335e-02, -9.4727e-02,\n",
      "         5.7028e-02, -2.1834e-01, -8.6906e-02, -1.7136e-01,  3.1509e-02,\n",
      "        -2.4328e-01,  1.2717e-01, -2.7517e-01,  1.1355e-01,  7.2316e-02,\n",
      "        -6.2715e-02, -8.2531e-05,  2.4591e-02,  9.6144e-02,  1.6482e-01,\n",
      "        -5.9063e-02,  1.2438e-01, -1.4141e-01,  8.2376e-02, -2.2025e-01,\n",
      "         1.2484e-01,  2.5828e-01, -5.4167e-03,  1.1375e-01, -3.1359e-01,\n",
      "         6.9226e-02,  2.8471e-01, -1.2272e-01,  7.5805e-02,  7.2266e-02,\n",
      "         8.4897e-02, -2.7768e-04,  2.5775e-01, -1.5961e-01, -4.6039e-02,\n",
      "        -4.0946e-02,  3.1743e-01,  3.2805e-02, -8.6378e-02, -1.2455e-01,\n",
      "         1.9436e-01, -6.2395e-02,  2.2647e-01,  1.5665e-01,  9.7514e-02,\n",
      "         5.9790e-02, -2.6351e-02, -1.8009e-01, -3.6610e-02,  1.9758e-01,\n",
      "        -5.2627e-02,  7.7833e-03, -8.4747e-02,  1.9796e-01, -1.6854e-01,\n",
      "         7.2871e-02,  2.2315e-01,  1.5805e-01,  6.3123e-03, -1.3764e-01,\n",
      "         8.3174e-02,  7.0579e-03,  4.2052e-02, -1.7173e-01, -1.9481e-02,\n",
      "        -1.6892e-01,  1.2533e-01,  3.8280e-02,  1.2346e-01, -1.2948e-01,\n",
      "        -1.8031e-01,  2.1381e-01,  2.3912e-01, -8.9418e-03, -1.5897e-01,\n",
      "         2.5432e-01,  2.5344e-02,  5.5943e-02,  7.7918e-02, -2.0473e-01,\n",
      "        -4.4029e-02, -1.2749e-01, -2.0348e-02, -2.3783e-02,  1.4201e-01,\n",
      "         1.1023e-01, -1.3934e-01,  1.2397e-01, -1.5630e-02,  4.8893e-02,\n",
      "         2.0409e-01,  1.4587e-01, -5.6078e-02, -4.7973e-02,  4.1586e-02,\n",
      "         5.4998e-02,  1.7261e-01,  9.6616e-02,  2.2183e-01,  1.7905e-01,\n",
      "        -3.2972e-01,  2.3572e-01, -2.7218e-02, -1.3957e-01,  1.0161e-02,\n",
      "         9.3559e-02, -7.5870e-02,  7.7917e-02,  4.4441e-02,  6.3936e-03,\n",
      "        -1.4353e-01,  3.5840e-02, -1.7984e-01,  1.5577e-01, -4.0589e-02,\n",
      "         9.0434e-03,  6.0281e-02,  2.3679e-01,  8.2679e-02, -5.5276e-02,\n",
      "         4.4311e-02, -9.5667e-02, -2.0627e-01, -1.0570e-01, -5.6318e-02,\n",
      "        -1.0392e-01, -1.6207e-01,  7.7672e-02,  1.0413e-01, -7.1949e-02,\n",
      "        -1.7872e-01])\n",
      "Dataset 3: REAL tensor([-0.0185, -0.0447,  0.0810,  0.0177,  0.0432, -0.0592, -0.0006, -0.1049,\n",
      "         0.0356, -0.1026,  0.1275,  0.1086, -0.0219, -0.1849,  0.0484,  0.0104,\n",
      "        -0.2792, -0.0391,  0.0861,  0.1672,  0.1144,  0.0080,  0.1012, -0.0894,\n",
      "         0.1191, -0.0201, -0.0870,  0.1103, -0.0414,  0.0136,  0.2472,  0.0746,\n",
      "        -0.0929,  0.0427,  0.1720,  0.0003,  0.0730, -0.0678, -0.1114, -0.0779,\n",
      "        -0.0422,  0.1832, -0.1121,  0.0414,  0.2110, -0.1200,  0.0343,  0.0573,\n",
      "        -0.2492,  0.0074,  0.0208,  0.0738,  0.0821,  0.0182, -0.1274, -0.0752,\n",
      "        -0.1240, -0.0303,  0.1587, -0.1422, -0.0563,  0.0058, -0.1914, -0.0132,\n",
      "         0.0901, -0.1718,  0.0807,  0.1080, -0.0236, -0.0524, -0.0881,  0.1826,\n",
      "         0.0681, -0.1560,  0.1618,  0.0078, -0.1217,  0.0161,  0.0182, -0.2574,\n",
      "         0.0993, -0.0286, -0.0955, -0.2358,  0.0129,  0.1053, -0.0581, -0.0602,\n",
      "        -0.0444,  0.0233, -0.2056,  0.1045, -0.0780, -0.0652,  0.0507, -0.0696,\n",
      "        -0.2699,  0.0465,  0.0869,  0.1492, -0.0569,  0.1731, -0.2519,  0.0286,\n",
      "        -0.0367, -0.0546,  0.0930,  0.0502,  0.2424, -0.0453,  0.0414, -0.0365,\n",
      "         0.0142, -0.0778,  0.0161, -0.1386, -0.0266, -0.1647, -0.0479,  0.0385,\n",
      "        -0.0167,  0.0258, -0.0620, -0.0532, -0.1571,  0.0793, -0.0789, -0.0791,\n",
      "         0.1749, -0.0644, -0.0361,  0.0714, -0.0052,  0.0060, -0.2123, -0.0513,\n",
      "         0.0528, -0.0123, -0.0060, -0.0298, -0.2752,  0.0837, -0.0072,  0.1445,\n",
      "         0.1066, -0.1299,  0.0588, -0.1864, -0.0225,  0.0949,  0.1374, -0.0392,\n",
      "         0.0681,  0.0372,  0.1626,  0.1205,  0.1020, -0.1172,  0.0693, -0.0981,\n",
      "         0.2218, -0.0203, -0.0356, -0.1986, -0.0286,  0.0700, -0.0302, -0.0479,\n",
      "         0.0265, -0.2114, -0.0660, -0.0994, -0.1048, -0.0382, -0.1739, -0.0589,\n",
      "        -0.1644,  0.0082, -0.2081,  0.0570, -0.0304,  0.0017, -0.0830, -0.0358,\n",
      "        -0.0270,  0.1082, -0.0006, -0.0731, -0.1959, -0.0278,  0.1348,  0.0933,\n",
      "        -0.0309, -0.0228, -0.1123,  0.2241, -0.0300,  0.1939, -0.0665,  0.0095,\n",
      "         0.1498, -0.1611, -0.1494, -0.0141,  0.0927,  0.0176, -0.2293, -0.0327,\n",
      "         0.0548, -0.0386,  0.0607,  0.0685,  0.0573, -0.1652, -0.2925, -0.0318,\n",
      "        -0.1264, -0.0586,  0.0139, -0.0884, -0.0572,  0.0086, -0.0213,  0.0925,\n",
      "        -0.0975, -0.1339,  0.0404,  0.0549, -0.0774, -0.1281,  0.0990, -0.0248,\n",
      "        -0.1250,  0.0751,  0.1186,  0.0140, -0.1761,  0.0549,  0.2283,  0.0955,\n",
      "        -0.0716,  0.1501,  0.0314, -0.1098, -0.1363, -0.0325, -0.0588,  0.0605,\n",
      "        -0.0902, -0.0329, -0.1265,  0.1474, -0.0371,  0.1615,  0.0918, -0.1019])\n",
      "Dataset 4: REAL tensor([ 4.4227e-02,  5.8688e-02,  5.9872e-02,  5.8048e-02,  1.1945e-03,\n",
      "        -1.6315e-01, -5.2223e-04,  1.8718e-02,  2.1622e-01,  7.7951e-02,\n",
      "         2.4210e-02, -1.1305e-01,  2.3980e-01,  1.1885e-01, -3.1770e-02,\n",
      "        -2.5433e-01, -7.8842e-02,  1.6972e-01,  9.9940e-02,  9.7711e-02,\n",
      "         5.5640e-02, -3.3990e-02, -6.2766e-02,  1.4112e-01,  1.5524e-01,\n",
      "         1.8099e-01,  9.0800e-02,  6.4529e-02, -4.8988e-02, -6.1190e-02,\n",
      "         1.8403e-02,  5.3221e-02, -2.0670e-01, -6.9463e-02, -6.5473e-02,\n",
      "        -4.5374e-02, -1.8390e-03,  2.0321e-02, -2.6514e-01,  2.8077e-02,\n",
      "        -2.1704e-02,  1.1310e-02, -1.8820e-01,  2.3876e-01,  9.7278e-02,\n",
      "        -2.0129e-01, -1.0889e-01,  7.8771e-02, -1.3330e-01,  2.1023e-01,\n",
      "         7.6139e-03,  1.2021e-01, -7.6398e-02, -8.6567e-02, -5.8146e-02,\n",
      "        -2.9345e-02, -8.7375e-02, -3.2176e-03,  4.7553e-02, -2.7312e-02,\n",
      "        -1.2481e-01,  1.2701e-01, -4.5437e-02,  4.3261e-02,  1.9424e-02,\n",
      "         3.6898e-02,  5.4780e-02, -1.7135e-01, -4.5427e-02, -2.6543e-02,\n",
      "         5.9881e-02,  1.6618e-01,  1.6253e-02, -7.7452e-02, -3.1186e-01,\n",
      "        -2.3575e-01, -2.1041e-01,  8.4703e-02, -1.9584e-01,  6.9703e-02,\n",
      "        -2.1784e-01,  3.9354e-02,  1.5266e-01,  2.2352e-01, -1.9347e-02,\n",
      "        -3.5374e-01, -1.6531e-01,  1.3894e-02, -9.4727e-03,  2.4663e-01,\n",
      "        -1.1270e-01,  8.9793e-02,  3.3749e-02, -2.2093e-01,  1.8401e-01,\n",
      "        -5.7991e-02, -3.5065e-01,  6.8772e-03,  5.6680e-02,  4.6469e-02,\n",
      "        -1.6437e-02, -7.5012e-02, -7.5196e-02, -1.3193e-01, -2.5126e-01,\n",
      "        -6.8502e-03,  1.5726e-01, -7.6548e-02,  6.0994e-05, -1.4070e-01,\n",
      "        -1.2810e-01, -3.5524e-02,  5.9499e-02,  1.2658e-01,  9.3801e-02,\n",
      "         2.4118e-01,  3.3082e-02,  9.0083e-02, -1.1213e-01,  2.3908e-01,\n",
      "         1.1711e-01,  1.5210e-01, -2.6108e-01,  6.5367e-02,  1.9531e-02,\n",
      "         3.7545e-04, -2.0218e-01, -1.0674e-01, -5.2263e-02,  8.6943e-02,\n",
      "         9.7343e-02,  2.4194e-01, -1.6441e-01,  1.3248e-01,  1.3692e-01,\n",
      "        -1.8089e-01,  9.0306e-02, -3.0813e-01,  2.5202e-02, -2.8964e-01,\n",
      "         4.1535e-02, -4.8989e-02, -6.0943e-02, -9.4579e-02, -1.9806e-01,\n",
      "        -8.0007e-02, -1.0275e-01, -6.8831e-02,  2.3272e-02, -2.7216e-02,\n",
      "        -8.7948e-02,  2.9730e-01,  1.4561e-01,  1.9857e-01,  1.2734e-01,\n",
      "        -2.2808e-01,  2.3235e-01,  1.1843e-01,  6.8817e-02, -6.0642e-02,\n",
      "        -5.3211e-02,  1.7821e-01, -1.1276e-01,  4.2480e-02,  2.4665e-02,\n",
      "        -7.5726e-02, -1.2764e-01, -2.0512e-01,  9.9384e-03,  1.4219e-01,\n",
      "        -1.1378e-01,  4.5680e-02,  8.2760e-02,  3.8197e-02,  6.4710e-02,\n",
      "        -1.8750e-01, -2.2171e-01,  1.3305e-01,  2.9608e-02,  1.1390e-01,\n",
      "        -2.2914e-02, -1.0807e-02, -2.1635e-02,  3.6096e-02,  2.0500e-01,\n",
      "         7.1400e-02,  6.0956e-02,  3.6218e-02, -2.0911e-01, -1.4093e-02,\n",
      "         4.0259e-02, -3.0409e-02,  5.2285e-02, -2.2657e-02, -1.1949e-01,\n",
      "        -1.1404e-01,  1.0150e-01,  2.0415e-01,  5.1678e-03,  1.9272e-02,\n",
      "         3.4947e-01,  1.0398e-01,  8.9595e-02,  4.1401e-03,  1.0373e-01,\n",
      "        -9.3139e-02, -1.0920e-01, -2.3647e-02, -9.3196e-03,  1.5879e-01,\n",
      "        -1.3535e-01, -2.8905e-02, -5.6458e-02,  9.1690e-02, -2.4493e-02,\n",
      "         5.8359e-02, -6.1857e-02, -1.1047e-01, -3.9407e-02,  2.3682e-01,\n",
      "         1.7981e-01,  2.6524e-01,  8.2917e-02, -1.8880e-02,  1.8532e-02,\n",
      "        -2.1553e-01,  3.0341e-01,  3.9911e-02,  4.5690e-02,  1.5164e-01,\n",
      "         2.8968e-02, -8.5927e-02,  1.1027e-01, -1.7192e-01,  1.5220e-01,\n",
      "         6.1799e-03,  1.3240e-01, -1.7399e-01,  1.1973e-01, -1.4347e-01,\n",
      "         1.8823e-01,  2.2663e-01,  1.5084e-02, -1.5917e-01,  1.0922e-01,\n",
      "         7.1469e-02,  6.8909e-02,  7.2151e-02, -4.3699e-02, -1.0194e-01,\n",
      "         6.4033e-02, -3.5928e-02, -1.1362e-01,  1.5544e-01, -4.9065e-03,\n",
      "        -2.3195e-01])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## DataLoader\n",
    "    - DataLoader는 구축된 데이터셋에서 배치크기(batch_size)에 맞게 데이터를 추출하고, 필요에 따라 섞거나(shuffle=True) 순서대로 반환(shuffle=False)하는 역할을 합니다.\n",
    "    - 훈련 데이터(train_loader)는 일반적으로 섞어서 모델이 데이터에 덜 편향되게 학습하도록하며,\n",
    "      검증 데이터(val_loader)는 모델 성능 평가를 위해 순서대로 사용하고,\n",
    "      테스트 데이터(test_loader)는 최종적인 추론을 위해 사용합니다.\n",
    "\n",
    "    이렇게 DataLoader를 사용함으로써, 효율적인 데이터 처리와 모델 학습 및 평가가 가능해집니다."
   ],
   "id": "270e0ffa984bb3a"
  },
  {
   "cell_type": "code",
   "id": "dff1c7df-fbe7-4a61-9f66-c55138697eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:50:49.702608Z",
     "start_time": "2024-07-04T20:50:49.696763Z"
    }
   },
   "source": [
    "BATCH_SIZE = CONFIG.BATCH_SIZE\n",
    "\n",
    "real_loader = DataLoader(real_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "augmt_loader = DataLoader(real_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "fake_loader = DataLoader(fake_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "effb3435-cdb7-4a31-b7ef-fc16237cfc4a",
   "metadata": {},
   "source": "## Define Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:26.211348Z",
     "start_time": "2024-07-04T20:28:26.203237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VoiceEncoder(nn.Module):\n",
    "    \"\"\" Voice Encoder Model \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        out = self.fc2(h1)\n",
    "        return F.sigmoid(out)"
   ],
   "id": "897283254be72389",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:26.218557Z",
     "start_time": "2024-07-04T20:28:26.212357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConstrastiveDistanceFunction(nn.Module):\n",
    "    \"\"\" Contrastive Distance Function \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_size, latent_size * 2)\n",
    "        self.fc2 = nn.Linear(latent_size * 2, latent_size)\n",
    "        self.out = nn.Linear(latent_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, anchor, comparative):\n",
    "        combined = self.relu(self.fc1(anchor + comparative))\n",
    "        output = self.relu(self.fc2(combined))\n",
    "        return F.sigmoid(self.out(output))"
   ],
   "id": "608c75bc69efb15f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "aba60869-b8a5-46c2-b185-00131161a158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:30.537881Z",
     "start_time": "2024-07-04T20:28:30.532955Z"
    }
   },
   "source": [
    "class BinaryDiscriminator(nn.Module):\n",
    "    \"\"\" Binary Discriminator Model using Contrastive Learning \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_size, latent_size):\n",
    "        super().__init__()\n",
    "        self.encoder = VoiceEncoder(embedding_dim, hidden_size, latent_size)\n",
    "        self.real_distance = ConstrastiveDistanceFunction(latent_size)\n",
    "        self.fake_distance = ConstrastiveDistanceFunction(latent_size)\n",
    "\n",
    "    def forward(self, anchor, comparative):\n",
    "        anchor = self.encoder(anchor)\n",
    "        return [self.real_distance(anchor, self.encoder(comp)) for comp in comparative], [self.fake_distance(anchor, self.encoder(comp)) for comp in comparative]"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:32.088050Z",
     "start_time": "2024-07-04T20:28:32.081752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 파라미터 지정\n",
    "model_params = dict(\n",
    "    embedding_dim=len(train_dataset[0][0]),\n",
    "    hidden_size=512,\n",
    "    latent_size=128\n",
    ")\n",
    "model_params"
   ],
   "id": "b803a71eb2decea0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 256, 'hidden_size': 512, 'latent_size': 128}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:33.381328Z",
     "start_time": "2024-07-04T20:28:33.103393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 생성\n",
    "voice_discrimination_model = BinaryDiscriminator(**model_params)\n",
    "discriminator = voice_discrimination_model\n",
    "discriminator.to(device)"
   ],
   "id": "8669c3af6468c5d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryDiscriminator(\n",
       "  (encoder): VoiceEncoder(\n",
       "    (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (real_distance): ConstrastiveDistanceFunction(\n",
       "    (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (fake_distance): ConstrastiveDistanceFunction(\n",
       "    (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:34.194346Z",
     "start_time": "2024-07-04T20:28:34.191132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BinaryCrossEntropy\n",
    "criterion = nn.BCELoss().to(device)"
   ],
   "id": "26c3d8aa65edbba",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:28:34.929232Z",
     "start_time": "2024-07-04T20:28:34.923668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=CONFIG.LR)"
   ],
   "id": "958745152fe04f4f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "b28c4a8c-0219-46bd-bd46-09d0327fe7eb",
   "metadata": {},
   "source": "## Train & Validation"
  },
  {
   "cell_type": "code",
   "id": "2a7253de-ce9a-45a8-b71f-7752e427941c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T21:15:14.672982Z",
     "start_time": "2024-07-04T21:02:39.226797Z"
    }
   },
   "source": [
    "epochs = CONFIG.N_EPOCHS\n",
    "batch_size = CONFIG.BATCH_SIZE\n",
    "train_amount = len(real_loader)\n",
    "valid_amount = len(valid_loader)\n",
    "anchor_sample = next(iter(real_loader))[0][0].to(device)\n",
    "\n",
    "#best_val_score = 0\n",
    "last_val_acc = 0\n",
    "\n",
    "loader_refresh = (epochs // 4, epochs // 4 * 2, epochs // 4 * 3)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Train\n",
    "    discriminator.train()\n",
    "    train_loss = [0, 0]\n",
    "    \n",
    "    if epoch in loader_refresh:\n",
    "        real_loader = DataLoader(real_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        augmt_loader = DataLoader(real_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        fake_loader = DataLoader(fake_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    for i, (real, augmt, fake) in enumerate(zip(real_loader, augmt_loader, fake_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        anchor, *_ = real\n",
    "        positive, *_ = augmt\n",
    "        negative, *_ = fake\n",
    "        \n",
    "        if anchor.shape[0] != positive.shape[0] or anchor.shape[0] != negative.shape[0]:\n",
    "            continue\n",
    "\n",
    "        real, fake = discriminator(anchor.to(device), [positive.to(device), negative.to(device)])\n",
    "        \n",
    "        positive_loss = criterion(real[0], torch.ones(real[0].shape).to(device))\n",
    "        negative_loss = criterion(real[1], torch.zeros(real[1].shape).to(device))\n",
    "        real_loss = positive_loss + negative_loss\n",
    "        \n",
    "        positive_loss = criterion(real[0], torch.ones(real[0].shape).to(device))\n",
    "        negative_loss = criterion(real[1], torch.zeros(real[1].shape).to(device))\n",
    "        fake_loss = positive_loss + negative_loss\n",
    "        \n",
    "        loss = real_loss + fake_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss[0] += real_loss.item()\n",
    "        train_loss[1] += fake_loss.item()\n",
    "        \n",
    "        print(f\"\\rEpoch [{epoch+1}/{epochs}], Step: [{i+1}/{train_amount}], Train Loss: {train_loss[0]/(i+1):.5f} | {train_loss[1]/(i+1):.5f}\", end=\"\")\n",
    "\n",
    "    # Validation\n",
    "    discriminator.eval()\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "\n",
    "    if (epoch+1) % 10 == 0 or epoch+1 == epochs:\n",
    "        with torch.no_grad():\n",
    "            for feature, label, _ in valid_loader:\n",
    "                feature, label = feature.to(device), label.to(device)\n",
    "                \n",
    "                real, fake = discriminator(anchor_sample, [feature])\n",
    "                real, fake, label = real[0][0], fake[0][0], label[0]\n",
    "                \n",
    "                real_loss = criterion(real, label.float())\n",
    "                fake_loss = criterion(fake, 1-label.float())\n",
    "                    \n",
    "                loss = real_loss + fake_loss\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                valid_acc += torch.eq(real*(1-fake) >= 0.5, label).sum().item() / batch_size\n",
    "    \n",
    "        print(f\"\\rEpoch [{epoch+1}/{epochs}], Step: [{train_amount}/{train_amount}], Train Loss: {train_loss[0]/train_amount:.5f} | {train_loss[1]/train_amount:.5f} => Valid Loss: {valid_loss/valid_amount:.5f}, Valid ACC: {valid_acc/valid_amount:.5%}\", end=\"    \\n\")\n",
    "        last_val_acc = f\"{valid_acc/valid_amount:.5%}\"[:-1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "454d6dc4f48d43bf8d89084d4d5386c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Step: [221/221], Train Loss: 0.00813 | 0.00813 => Valid Loss: 0.70945, Valid ACC: 0.50108%    \n",
      "Epoch [20/200], Step: [221/221], Train Loss: 0.00751 | 0.00751 => Valid Loss: 0.70663, Valid ACC: 0.50108%    \n",
      "Epoch [30/200], Step: [221/221], Train Loss: 0.00523 | 0.00523 => Valid Loss: 0.70543, Valid ACC: 0.50108%    \n",
      "Epoch [40/200], Step: [221/221], Train Loss: 0.00491 | 0.00491 => Valid Loss: 0.70727, Valid ACC: 0.50108%    \n",
      "Epoch [50/200], Step: [221/221], Train Loss: 0.00338 | 0.00338 => Valid Loss: 0.70673, Valid ACC: 0.50108%    \n",
      "Epoch [60/200], Step: [221/221], Train Loss: 0.00315 | 0.00315 => Valid Loss: 0.70665, Valid ACC: 0.50108%    \n",
      "Epoch [70/200], Step: [221/221], Train Loss: 0.00207 | 0.00207 => Valid Loss: 0.70632, Valid ACC: 0.50108%    \n",
      "Epoch [80/200], Step: [221/221], Train Loss: 0.00200 | 0.00200 => Valid Loss: 0.70522, Valid ACC: 0.50108%    \n",
      "Epoch [90/200], Step: [221/221], Train Loss: 0.00155 | 0.00155 => Valid Loss: 0.70665, Valid ACC: 0.50108%    \n",
      "Epoch [100/200], Step: [221/221], Train Loss: 0.00101 | 0.00101 => Valid Loss: 0.70555, Valid ACC: 0.50108%    \n",
      "Epoch [110/200], Step: [221/221], Train Loss: 0.00093 | 0.00093 => Valid Loss: 0.70611, Valid ACC: 0.50108%    \n",
      "Epoch [120/200], Step: [221/221], Train Loss: 0.00087 | 0.00087 => Valid Loss: 0.70641, Valid ACC: 0.50108%    \n",
      "Epoch [130/200], Step: [221/221], Train Loss: 0.00054 | 0.00054 => Valid Loss: 0.70524, Valid ACC: 0.50108%    \n",
      "Epoch [140/200], Step: [221/221], Train Loss: 0.00033 | 0.00033 => Valid Loss: 0.70605, Valid ACC: 0.50108%    \n",
      "Epoch [150/200], Step: [221/221], Train Loss: 0.00043 | 0.00043 => Valid Loss: 0.70556, Valid ACC: 0.50108%    \n",
      "Epoch [160/200], Step: [221/221], Train Loss: 0.00035 | 0.00035 => Valid Loss: 0.70556, Valid ACC: 0.50108%    \n",
      "Epoch [170/200], Step: [221/221], Train Loss: 0.00044 | 0.00044 => Valid Loss: 0.70659, Valid ACC: 0.50108%    \n",
      "Epoch [180/200], Step: [221/221], Train Loss: 0.00040 | 0.00040 => Valid Loss: 0.70538, Valid ACC: 0.50108%    \n",
      "Epoch [190/200], Step: [221/221], Train Loss: 0.00046 | 0.00046 => Valid Loss: 0.70603, Valid ACC: 0.50108%    \n",
      "Epoch [200/200], Step: [221/221], Train Loss: 0.00017 | 0.00017 => Valid Loss: 0.70622, Valid ACC: 0.50108%    \n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model Save\n",
    "save_path = os.path.join(\".\", \"models\", f\"contrastive_model_acc_{last_val_acc}.pt\")\n",
    "torch.save(discriminator.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ],
   "id": "f49b0f23f044b1f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a978b0e6-b773-423a-93e4-ce463f4d4d84",
   "metadata": {},
   "source": [
    "### Inference\n",
    "테스트 데이터셋에 대한 추론은 다음 순서로 진행됩니다.\n",
    "\n",
    "1. 모델 및 디바이스 설정\n",
    "    - 모델을 주어진 device(GPU 또는 CPU)로 이동시키고, 평가모드로 전환합니다.\n",
    "2. 예측 수행\n",
    "    - 예측 결과를 저장한 빈 리스트를 초기화하고 test_loader에서 배치별로 데이터를 불러와 예측을 수행합니다.\n",
    "    - 각 배치에 대해 스펙트로그램 데이터를 device로 이동시킵니다.\n",
    "    - 모델 예측 확률(probs)을 계산합니다.\n",
    "    - 예측 확률을 predictions리스트에 추가합니다."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set Model ID\n",
    "model_id = \"contrastive_model_acc_99.66667\""
   ],
   "id": "f20c8e943ad22b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Model\n",
    "discriminator = BinaryDiscriminator(**model_params)\n",
    "discriminator.load_state_dict(torch.load(os.path.join(\".\", \"models\", f\"{model_id}.pt\")))\n",
    "discriminator.to(device)"
   ],
   "id": "a7711cfa292ee987",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from speechbrain.inference.VAD import VAD\n",
    "\n",
    "def vad_filter(\n",
    "        dataset, use_preset=True,\n",
    "        filter_model=VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir='./.cache/vad-crdnn-libriparty', run_opts={\"device\":\"cuda\"})\n",
    "):\n",
    "    def query_preset(_id: str, index: int, *args, **kwargs):\n",
    "        return dataset.label[index][int(_id.replace(\"TEST_\", \"\"))]\n",
    "    \n",
    "    def vad(_id: str, index: int, activation_th=0.4):\n",
    "        file_path = os.path.join(\".\", \"test_separated\", _id, f\"{index}\", \".16hz.ogg\")\n",
    "        boundaries = filter_model.get_speech_segments(file_path.replace(\"ogg\", \"16hz.ogg\"), activation_th=activation_th)\n",
    "        label = \"noise\"\n",
    "        last_end = 0\n",
    "        for i in range(boundaries.shape[0]):\n",
    "            begin_value = boundaries[i, 0]\n",
    "            end_value = boundaries[i, 1]\n",
    "            if last_end == begin_value:\n",
    "                label = \"speech\"\n",
    "            last_end = end_value\n",
    "        return label\n",
    "    \n",
    "    return query_preset if use_preset else vad"
   ],
   "id": "61716d1efabf39a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5889b493-d760-4cac-9ced-c3715195e8be",
   "metadata": {},
   "source": [
    "predicted_labels = []\n",
    "anchor_sample = next(iter(real_dataset))[0].to(device)\n",
    "vad = vad_filter(test_dataset, use_preset=True)\n",
    "\n",
    "discriminator.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs in tqdm(test_loader):\n",
    "        if test_dataset.multi_label:\n",
    "            features, _, ids = inputs\n",
    "            ids = ids[0]\n",
    "        else:  # TODO: Non-Multi-Label Test\n",
    "            raise NotImplemented(\"Test for Non-Multi-Label is not yet implemented.\")\n",
    "        \n",
    "        filtered = []\n",
    "        \n",
    "        for idx, feature in enumerate(features):\n",
    "            feature = feature[0].to(device)\n",
    "            if vad(ids, idx) == \"speech\":\n",
    "                filtered.append(feature)\n",
    "\n",
    "        predicted = discriminator(anchor_sample, filtered)\n",
    "        possibilities = [torch.tensor(1), torch.tensor(1)]  # positive, fake\n",
    "\n",
    "        if len(predicted) == 0:\n",
    "            positive, negative = 0, 0\n",
    "        elif len(predicted) == 1:\n",
    "            positive, negative = (1, 0) if predicted[0] >= 0.5 else (0, 1)\n",
    "        else:\n",
    "            is_positive0, is_positive1 = predicted[0] >= 0.5, predicted[1] >= 0.5\n",
    "            \n",
    "            if is_positive0 and is_positive1:\n",
    "                positive, negative = 1, 0\n",
    "            elif is_positive0 and not is_positive1:\n",
    "                positive, negative = 1, 1-predicted[1][0]\n",
    "            elif not is_positive0 and is_positive1:\n",
    "                positive, negative = 1-predicted[0][0], 1\n",
    "            else:\n",
    "                positive, negative = 0, 1\n",
    "        \n",
    "        predicted_labels += [(torch.tensor(positive), torch.tensor(negative))]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predicted_labels",
   "id": "a43eff05f21a91e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8fae66d-8f54-46d5-9201-0f4b0db76e76",
   "metadata": {},
   "source": [
    "### Submission\n",
    "추론 결과를 제출 양식에 덮어 씌워 CSV 파일로 생성하는 과정은 다음과 같습니다.\n",
    "\n",
    "1. 제출 양식 로드\n",
    "    - pd.read_csv('./sample_submission.csv')를 사용하여 제출을 위한 샘플 형식 파일을 로드합니다.\n",
    "    - 이 파일은 일반적으로 각 테스트 샘플에 대한 ID와 예측해야 하는 필드가 포함된 템플릿 형태를 가지고 있습니다.\n",
    "2. 예측 결과 할당\n",
    "    - submit.iloc[:,1:] = preds 추론함수(inference)에서 반환된 예측결과(preds)를 샘플 제출 파일에 2번째 열부터 할당합니다.\n",
    "3. 제출 파일 저장\n",
    "    - 수정된 제출 파일을 baseline_submit 이란 이름의 CSV 파일로 저장합니다.\n",
    "    - index=False는 파일 저장시 추가적인 index가 발생하지 않도록 설정하여, 제작한 제출 파일과 동일한 형태의 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "id": "3f8314c4-1dce-4f79-9f3d-77d320a3746e",
   "metadata": {},
   "source": [
    "submit = pd.read_csv(test_dataset.submission_form_path)\n",
    "submit.iloc[:, 1:] = torch.tensor(predicted_labels).cpu().numpy()\n",
    "submit.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e28d71bc-6703-40f7-9716-a0ef897eca83",
   "metadata": {},
   "source": "submit.to_csv(f\"{model_id}_submit.csv\", index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "489f16cad403e4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 4732842,
     "sourceId": 8066583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1830.928153,
   "end_time": "2024-04-08T19:22:15.265404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T18:51:44.337251",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01a8f214ec354c44b73d439565382278": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06a1ede084cd487ebf3c469be657b53e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80013ce73542415e82be091acccb89fe",
        "IPY_MODEL_d280070ca871485fbd2b7d34b1c9fd10",
        "IPY_MODEL_8212bde7695f494cbabea66983e4cf29"
       ],
       "layout": "IPY_MODEL_c4da594b806c4c2bbff6e8cdaf6088eb"
      }
     },
     "37e28ba3d8564da4a3257c3729310584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80013ce73542415e82be091acccb89fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95e72a34a4374fd5b4b147772085bb7c",
       "placeholder": "​",
       "style": "IPY_MODEL_37e28ba3d8564da4a3257c3729310584",
       "value": "model.safetensors: 100%"
      }
     },
     "8212bde7695f494cbabea66983e4cf29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d9e4e04bb60e40d6b46d782f8156d05f",
       "placeholder": "​",
       "style": "IPY_MODEL_b1fa83d0511a4d8a910b8fdb40d32c29",
       "value": " 36.5M/36.5M [00:01&lt;00:00, 41.1MB/s]"
      }
     },
     "95e72a34a4374fd5b4b147772085bb7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1fa83d0511a4d8a910b8fdb40d32c29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4da594b806c4c2bbff6e8cdaf6088eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d280070ca871485fbd2b7d34b1c9fd10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01a8f214ec354c44b73d439565382278",
       "max": 36494688,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dcd2393d73d14514851a7d9ef50315fc",
       "value": 36494688
      }
     },
     "d9e4e04bb60e40d6b46d782f8156d05f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcd2393d73d14514851a7d9ef50315fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
